{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9496aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "from os.path import join\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d65ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = ['angry','calm','disgust','fearful','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd35405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e6f2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Number of trainable params:  101736\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class ParallelModel(nn.Module):\n",
    "    def __init__(self,num_emotions):\n",
    "        super().__init__()\n",
    "       \n",
    "        \n",
    "       # 1. 1stage (Conv + BatchNorm + ReLU + Maxpooling + Dropout)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2,padding=0),\n",
    "            nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Dropout2d(p=0.3)\n",
    "        )\n",
    "                    \n",
    "        \n",
    "        \n",
    "        \n",
    "        # 2. 2stage (Conv + BatchNorm + ReLU + Maxpooling + Dropout)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(4,4), stride=4,padding=0),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Dropout2d(p=0.3)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # 3. 3stage (Conv + BatchNorm + ReLU + Maxpooling + Dropout)\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(4,4), stride=4,padding=0),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Dropout2d(p=0.3)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # 4. 4stage (Conv + BatchNorm + ReLU + Maxpooling + Dropout)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(4,4), stride=4,padding=0),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Dropout2d(p=0.3)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(1*4*128,8,bias=True)\n",
    "        nn.init.orthogonal_(self.fc.weight)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Linear softmax layer\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "    ##Forward\n",
    "        output = self.layer1(x)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = self.layer4(output)\n",
    "        output = output.view(output.size(0),-1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "model = ParallelModel(num_emotions=8).to(device)\n",
    "print('Number of trainable params: ',sum(p.numel() for p in model.parameters()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f11365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\arz61\\Documents\\오픈소스'\n",
    "model = torch.load(os.path.join(path,'model_300.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6486dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/arz61/OneDrive/바탕 화면/4학년 1학기 홍혁기/오픈소스SW개론/melon chart/음성인식을통한 감정분류'\n",
    "file_list = os.listdir(path)\n",
    "file_list_py = [file for file in file_list if file.endswith('.csv')] ## 파일명 끝이 .csv인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1e99c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_sample = pd.read_csv(path + '/' +file_list_py[0])\n",
    "pd_test = pd.read_csv(path + '/' +file_list_py[1])\n",
    "pd_train = pd.read_csv(path + '/' +file_list_py[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a5fea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, librosa.display \n",
    "\n",
    "def load_audiofiles(file_name, sample_rate=48000):\n",
    "    \n",
    "    result=np.array([])\n",
    "    \n",
    "    audio_signal, sample_rate = librosa.load(file_name, duration=3, offset=0.5, sr=sample_rate)\n",
    "\n",
    "    signal = np.zeros(int(sample_rate*3,))\n",
    "    signal[:len(audio_signal)] = audio_signal\n",
    "    \n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "217c1233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1008it [05:43,  2.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 432/432 [02:21<00:00,  3.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def load_data(data_info, isTrain=True):\n",
    "    \n",
    "    PATH = \"C:/Users/arz61/OneDrive/바탕 화면/4학년 1학기 홍혁기/오픈소스SW개론/melon chart/음성인식을통한 감정분류\"\n",
    "    if isTrain:\n",
    "        train_data = []#음성 feature들을 담는 dictionary\n",
    "        train_label = []#학습에 사용할 label을 담는 list\n",
    "        \n",
    "        file_list = data_info['file_name']\n",
    "        emotion_list = data_info['emotion']\n",
    "        for file_name, emotion in tqdm(zip(file_list, emotion_list)):\n",
    "            \n",
    "            hi=join(PATH, 'train_data',file_name)\n",
    "            train_data.append(load_audiofiles(hi))\n",
    "            train_label.append(emotion)\n",
    "            \n",
    "        return np.array(train_data), np.array(train_label)\n",
    "    \n",
    "    else:\n",
    "        test_data = []\n",
    "        file_list = data_info['file_name']\n",
    "    \n",
    "        for file_name in tqdm(file_list):\n",
    "\n",
    "            hi=join(PATH, 'test_data',file_name)\n",
    "            test_data.append(load_audiofiles(hi))\n",
    "            \n",
    "        return np.array(test_data)\n",
    "\n",
    "#DataFlair - Split the dataset\n",
    "train_data, train_label = load_data(pd_train)\n",
    "test_data = load_data(pd_test, isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31059c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate mel spectrograms for train set\n",
      " Processed 1008/1008 files\n",
      " Processed 432/432 files\n",
      "mel_train:(1008, 128, 563), mel_test:(432, 128, 563)\n"
     ]
    }
   ],
   "source": [
    "def Calculate_Melspectrogram(audio, sample_rate):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio,\n",
    "                                              sr=sample_rate,\n",
    "                                              n_fft=1024,\n",
    "                                              win_length = 512,\n",
    "                                              window='hamming',\n",
    "                                              hop_length = 256,\n",
    "                                              n_mels=128,\n",
    "                                              fmax=sample_rate/2\n",
    "                                             )\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db\n",
    "\n",
    "mel_train = []\n",
    "print(\"Calculate mel spectrograms for train set\")\n",
    "train_data = np.stack(np.array(train_data),0)\n",
    "test_data = np.stack(np.array(test_data),0)\n",
    "for i in range(train_data.shape[0]):\n",
    "    mel_spectrogram = Calculate_Melspectrogram(train_data[i,:], sample_rate=48000)\n",
    "    mel_train.append(mel_spectrogram)\n",
    "    print(\"\\r Processed {}/{} files\".format(i+1,train_data.shape[0]),end='')\n",
    "    \n",
    "print('')\n",
    "mel_train = np.stack(mel_train,axis=0)\n",
    "\n",
    "mel_test = []\n",
    "for i in range(test_data.shape[0]):\n",
    "    mel_spectrogram = Calculate_Melspectrogram(test_data[i,:], sample_rate=48000)\n",
    "    mel_test.append(mel_spectrogram)\n",
    "    print(\"\\r Processed {}/{} files\".format(i+1,test_data.shape[0]),end='')\n",
    "    \n",
    "print('')\n",
    "mel_test = np.stack(mel_test,axis=0)\n",
    "\n",
    "print(f'mel_train:{mel_train.shape}, mel_test:{mel_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf189001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_train = np.expand_dims(mel_train, 1) #DataNum, 1ch, H, W\n",
    "x_test = np.expand_dims(mel_test, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "b,c,h,w = x_train.shape\n",
    "x_train = np.reshape(x_train, newshape=(b,-1))\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_train = np.reshape(x_train, newshape=(b,c,h,w))\n",
    "\n",
    "b,c,h,w = x_test.shape\n",
    "x_test = np.reshape(x_test, newshape=(b,-1))\n",
    "x_test = scaler.transform(x_test)\n",
    "x_test = np.reshape(x_test, newshape=(b,c,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd935a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 432/432 [00:23<00:00, 18.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_len:432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "predicts = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(x_test):\n",
    "        ###test data를 하나씩 불러와서 학습된 모델로 추론 후 predicts array에 저장합니다.\n",
    "        t = torch.Tensor(np.expand_dims(data, 0)).to(device)\n",
    "        H = model(t)\n",
    "        predict = torch.argmax(H, 1).cpu().detach().numpy()[0]\n",
    "        predicts.append(predict)\n",
    "        \n",
    "print(f'predict_len:{len(predicts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9a7e242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sad', 'sad', 'calm', 'calm', 'disgust', 'sad', 'disgust', 'angry',\n",
       "       'happy', 'sad', 'fearful', 'angry', 'surprise', 'surprise',\n",
       "       'surprise', 'sad', 'disgust', 'calm', 'happy', 'sad', 'angry',\n",
       "       'sad', 'fearful', 'neutral', 'surprise', 'sad', 'happy', 'fearful',\n",
       "       'happy', 'neutral', 'sad', 'surprise', 'calm', 'sad', 'disgust',\n",
       "       'happy', 'calm', 'happy', 'disgust', 'sad', 'sad', 'disgust',\n",
       "       'fearful', 'angry', 'disgust', 'angry', 'neutral', 'surprise',\n",
       "       'surprise', 'happy', 'happy', 'happy', 'disgust', 'happy',\n",
       "       'fearful', 'calm', 'angry', 'angry', 'surprise', 'calm', 'sad',\n",
       "       'angry', 'surprise', 'surprise', 'sad', 'angry', 'surprise',\n",
       "       'disgust', 'fearful', 'happy', 'angry', 'surprise', 'angry',\n",
       "       'surprise', 'sad', 'happy', 'calm', 'happy', 'surprise', 'disgust',\n",
       "       'sad', 'fearful', 'disgust', 'calm', 'calm', 'angry', 'angry',\n",
       "       'disgust', 'disgust', 'disgust', 'happy', 'sad', 'angry',\n",
       "       'neutral', 'fearful', 'calm', 'fearful', 'happy', 'calm',\n",
       "       'fearful', 'happy', 'calm', 'disgust', 'calm', 'neutral', 'angry',\n",
       "       'calm', 'calm', 'angry', 'happy', 'neutral', 'calm', 'neutral',\n",
       "       'surprise', 'fearful', 'disgust', 'surprise', 'happy', 'fearful',\n",
       "       'sad', 'angry', 'calm', 'calm', 'happy', 'surprise', 'calm',\n",
       "       'fearful', 'calm', 'disgust', 'sad', 'calm', 'angry', 'calm',\n",
       "       'disgust', 'happy', 'neutral', 'happy', 'sad', 'calm', 'happy',\n",
       "       'disgust', 'happy', 'calm', 'neutral', 'fearful', 'disgust',\n",
       "       'surprise', 'happy', 'fearful', 'surprise', 'fearful', 'sad',\n",
       "       'disgust', 'sad', 'sad', 'calm', 'neutral', 'happy', 'surprise',\n",
       "       'angry', 'sad', 'fearful', 'fearful', 'neutral', 'angry', 'calm',\n",
       "       'neutral', 'angry', 'surprise', 'angry', 'angry', 'angry',\n",
       "       'disgust', 'angry', 'happy', 'angry', 'disgust', 'surprise',\n",
       "       'disgust', 'angry', 'calm', 'happy', 'calm', 'disgust', 'happy',\n",
       "       'disgust', 'fearful', 'calm', 'calm', 'disgust', 'disgust', 'calm',\n",
       "       'calm', 'surprise', 'angry', 'happy', 'angry', 'neutral', 'angry',\n",
       "       'disgust', 'angry', 'calm', 'neutral', 'disgust', 'disgust',\n",
       "       'fearful', 'disgust', 'fearful', 'angry', 'calm', 'calm', 'angry',\n",
       "       'angry', 'angry', 'surprise', 'calm', 'disgust', 'angry', 'sad',\n",
       "       'angry', 'surprise', 'disgust', 'disgust', 'disgust', 'fearful',\n",
       "       'fearful', 'fearful', 'calm', 'angry', 'fearful', 'fearful', 'sad',\n",
       "       'calm', 'surprise', 'calm', 'angry', 'fearful', 'fearful',\n",
       "       'surprise', 'surprise', 'calm', 'disgust', 'fearful', 'disgust',\n",
       "       'calm', 'angry', 'surprise', 'disgust', 'surprise', 'happy',\n",
       "       'calm', 'neutral', 'angry', 'surprise', 'surprise', 'fearful',\n",
       "       'sad', 'disgust', 'calm', 'surprise', 'angry', 'calm', 'sad',\n",
       "       'angry', 'fearful', 'sad', 'sad', 'happy', 'disgust', 'neutral',\n",
       "       'fearful', 'sad', 'surprise', 'calm', 'neutral', 'angry',\n",
       "       'surprise', 'disgust', 'fearful', 'fearful', 'angry', 'surprise',\n",
       "       'surprise', 'surprise', 'surprise', 'surprise', 'sad', 'calm',\n",
       "       'neutral', 'happy', 'sad', 'neutral', 'disgust', 'fearful',\n",
       "       'surprise', 'fearful', 'sad', 'surprise', 'fearful', 'happy',\n",
       "       'sad', 'sad', 'happy', 'angry', 'fearful', 'fearful', 'sad',\n",
       "       'fearful', 'calm', 'surprise', 'fearful', 'fearful', 'neutral',\n",
       "       'fearful', 'angry', 'fearful', 'happy', 'neutral', 'disgust',\n",
       "       'happy', 'sad', 'surprise', 'calm', 'surprise', 'calm', 'angry',\n",
       "       'happy', 'neutral', 'surprise', 'disgust', 'sad', 'surprise',\n",
       "       'calm', 'surprise', 'disgust', 'happy', 'angry', 'happy', 'angry',\n",
       "       'disgust', 'disgust', 'surprise', 'neutral', 'surprise', 'angry',\n",
       "       'surprise', 'neutral', 'neutral', 'happy', 'fearful', 'calm',\n",
       "       'happy', 'disgust', 'angry', 'happy', 'neutral', 'fearful',\n",
       "       'happy', 'calm', 'calm', 'fearful', 'neutral', 'angry', 'angry',\n",
       "       'neutral', 'neutral', 'happy', 'disgust', 'happy', 'disgust',\n",
       "       'calm', 'disgust', 'calm', 'calm', 'sad', 'angry', 'angry',\n",
       "       'fearful', 'sad', 'sad', 'happy', 'calm', 'happy', 'happy',\n",
       "       'happy', 'calm', 'neutral', 'calm', 'disgust', 'angry', 'fearful',\n",
       "       'calm', 'calm', 'angry', 'fearful', 'calm', 'happy', 'surprise',\n",
       "       'angry', 'calm', 'happy', 'disgust', 'happy', 'calm', 'sad',\n",
       "       'surprise', 'neutral', 'happy', 'calm', 'sad', 'disgust', 'angry',\n",
       "       'happy', 'happy', 'neutral', 'disgust', 'surprise', 'fearful',\n",
       "       'angry', 'calm', 'calm', 'disgust', 'neutral', 'disgust',\n",
       "       'disgust', 'calm', 'surprise', 'calm', 'fearful', 'surprise',\n",
       "       'calm', 'angry'], dtype='<U8')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###저장된 예측값을 위에서 사용한 label encoder를 이용해 다시 문자열로 역변환합니다.\n",
    "predicts1 = le.inverse_transform(predicts)\n",
    "predicts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41ef0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/arz61/OneDrive/바탕 화면/4학년 1학기 홍혁기/오픈소스SW개론/melon chart/음성인식을통한 감정분류'\n",
    "sound = []\n",
    "hi=join(path, 'test5.wav')\n",
    "sound.append(load_audiofiles(hi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "665af142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.00308732, 0.00332645, 0.00319009, ..., 0.        , 0.        ,\n",
       "        0.        ])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2921a73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mel_sound:(1, 128, 563)\n"
     ]
    }
   ],
   "source": [
    "def Calculate_Melspectrogram(audio, sample_rate):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio,\n",
    "                                              sr=sample_rate,\n",
    "                                              n_fft=1024,\n",
    "                                              win_length = 512,\n",
    "                                              window='hamming',\n",
    "                                              hop_length = 256,\n",
    "                                              n_mels=128,\n",
    "                                              fmax=sample_rate/2\n",
    "                                             )\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db\n",
    "\n",
    "mel_sound = []\n",
    "mel_spectrogram = Calculate_Melspectrogram(sound[0], sample_rate=48000)\n",
    "mel_sound.append(mel_spectrogram)\n",
    "mel_sound = np.stack(mel_sound,axis=0)\n",
    "\n",
    "print(f'mel_sound:{mel_sound.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8931b37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 563)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_sound.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85820312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_sound = np.expand_dims(mel_sound, 1)\n",
    "\n",
    "b,c,h,w = x_sound.shape\n",
    "x_sound = np.reshape(x_sound, newshape=(b,-1))\n",
    "x_sound = scaler.transform(x_sound)\n",
    "x_sound = np.reshape(x_sound, newshape=(b,c,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a989d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts1 = []\n",
    "\n",
    "t = torch.Tensor(np.expand_dims(x_sound[0], 0)).to(device)\n",
    "H = model(t)\n",
    "predict1 = torch.argmax(H, 1).cpu().detach().numpy()[0]\n",
    "predicts1.append(predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e642d9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9cdd10f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = le.inverse_transform(predicts1)\n",
    "answer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aced97c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
