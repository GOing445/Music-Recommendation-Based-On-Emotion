{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce343557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12cee6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/arz61/OneDrive/바탕 화면/4학년 1학기 홍혁기/오픈소스SW개론/melon chart/음성인식을통한 감정분류'\n",
    "file_list = os.listdir(path)\n",
    "file_list_py = [file for file in file_list if file.endswith('.csv')] ## 파일명 끝이 .csv인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b6ee47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submit.csv', 'test_data.csv', 'train_data.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58ab667",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_sample = pd.read_csv(path + '/' +file_list_py[0])\n",
    "pd_test = pd.read_csv(path + '/' +file_list_py[1])\n",
    "pd_train = pd.read_csv(path + '/' +file_list_py[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ca288d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>file_name</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train_000.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train_001.wav</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>train_002.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>train_003.wav</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>train_004.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>train_1003.wav</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>train_1004.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1005</td>\n",
       "      <td>train_1005.wav</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1006</td>\n",
       "      <td>train_1006.wav</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1007</td>\n",
       "      <td>train_1007.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID       file_name    emotion\n",
       "0        0   train_000.wav    disgust\n",
       "1        1   train_001.wav  surprised\n",
       "2        2   train_002.wav    disgust\n",
       "3        3   train_003.wav       calm\n",
       "4        4   train_004.wav    neutral\n",
       "...    ...             ...        ...\n",
       "1003  1003  train_1003.wav       calm\n",
       "1004  1004  train_1004.wav    disgust\n",
       "1005  1005  train_1005.wav       calm\n",
       "1006  1006  train_1006.wav    fearful\n",
       "1007  1007  train_1007.wav    neutral\n",
       "\n",
       "[1008 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7329ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, librosa.display \n",
    "\n",
    "def load_audiofiles(file_name, sample_rate=48000):\n",
    "    \n",
    "    result=np.array([])\n",
    "    \n",
    "    audio_signal, sample_rate = librosa.load(file_name, duration=3, offset=0.5, sr=sample_rate)\n",
    "\n",
    "    signal = np.zeros(int(sample_rate*3,))\n",
    "    signal[:len(audio_signal)] = audio_signal\n",
    "    \n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ce66f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1008it [03:20,  5.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 432/432 [01:19<00:00,  5.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def load_data(data_info, isTrain=True):\n",
    "    \n",
    "    PATH = \"C:/Users/arz61/OneDrive/바탕 화면/4학년 1학기 홍혁기/오픈소스SW개론/melon chart/음성인식을통한 감정분류\"\n",
    "    if isTrain:\n",
    "        train_data = []#음성 feature들을 담는 dictionary\n",
    "        train_label = []#학습에 사용할 label을 담는 list\n",
    "        \n",
    "        file_list = data_info['file_name']\n",
    "        emotion_list = data_info['emotion']\n",
    "        for file_name, emotion in tqdm(zip(file_list, emotion_list)):\n",
    "            \n",
    "            hi=join(PATH, 'train_data',file_name)\n",
    "            train_data.append(load_audiofiles(hi))\n",
    "            train_label.append(emotion)\n",
    "            \n",
    "        return np.array(train_data), np.array(train_label)\n",
    "    \n",
    "    else:\n",
    "        test_data = []\n",
    "        file_list = data_info['file_name']\n",
    "    \n",
    "        for file_name in tqdm(file_list):\n",
    "\n",
    "            hi=join(PATH, 'test_data',file_name)\n",
    "            test_data.append(load_audiofiles(hi))\n",
    "            \n",
    "        return np.array(test_data)\n",
    "\n",
    "#DataFlair - Split the dataset\n",
    "train_data, train_label = load_data(pd_train)\n",
    "test_data = load_data(pd_test, isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1dfaaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 144000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1a7f27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.21018543e-04, -5.15965861e-04, -5.37155895e-04, ...,\n",
       "        -9.78065189e-04, -6.88828528e-04, -3.30862240e-04],\n",
       "       [-1.15136247e-08,  4.21569126e-08,  6.17588469e-08, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 7.13343837e-08,  3.70527360e-08, -3.60984380e-08, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.36580125e-08,  1.32046818e-08,  3.05960057e-08, ...,\n",
       "        -3.13619967e-05, -2.56385829e-05, -1.22153560e-05],\n",
       "       [ 9.28298562e-07,  1.53020142e-06,  7.74799958e-07, ...,\n",
       "        -2.93038484e-05, -2.06224486e-05, -1.00194056e-05]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3a24b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(train_label)\n",
    "y_train = le.transform(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd20f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "080bd5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate mel spectrograms for train set\n",
      " Processed 1008/1008 files\n",
      " Processed 432/432 files\n",
      "mel_train:(1008, 128, 563), mel_test:(432, 128, 563)\n"
     ]
    }
   ],
   "source": [
    "def Calculate_Melspectrogram(audio, sample_rate):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio,\n",
    "                                              sr=sample_rate,\n",
    "                                              n_fft=1024,\n",
    "                                              win_length = 512,\n",
    "                                              window='hamming',\n",
    "                                              hop_length = 256,\n",
    "                                              n_mels=128,\n",
    "                                              fmax=sample_rate/2\n",
    "                                             )\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db\n",
    "\n",
    "mel_train = []\n",
    "print(\"Calculate mel spectrograms for train set\")\n",
    "train_data = np.stack(np.array(train_data),0)\n",
    "test_data = np.stack(np.array(test_data),0)\n",
    "for i in range(train_data.shape[0]):\n",
    "    mel_spectrogram = Calculate_Melspectrogram(train_data[i,:], sample_rate=48000)\n",
    "    mel_train.append(mel_spectrogram)\n",
    "    print(\"\\r Processed {}/{} files\".format(i+1,train_data.shape[0]),end='')\n",
    "    \n",
    "print('')\n",
    "mel_train = np.stack(mel_train,axis=0)\n",
    "\n",
    "mel_test = []\n",
    "for i in range(test_data.shape[0]):\n",
    "    mel_spectrogram = Calculate_Melspectrogram(test_data[i,:], sample_rate=48000)\n",
    "    mel_test.append(mel_spectrogram)\n",
    "    print(\"\\r Processed {}/{} files\".format(i+1,test_data.shape[0]),end='')\n",
    "    \n",
    "print('')\n",
    "mel_test = np.stack(mel_test,axis=0)\n",
    "\n",
    "print(f'mel_train:{mel_train.shape}, mel_test:{mel_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "596a6316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 563)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "566db93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-80.        , -75.36580791, -68.47561208, ..., -47.22450878,\n",
       "        -47.62438774, -48.95785169],\n",
       "       [-80.        , -75.3591427 , -68.64603193, ..., -47.45657574,\n",
       "        -47.85619694, -49.14887196],\n",
       "       [-80.        , -72.58519013, -69.14501489, ..., -50.19153345,\n",
       "        -50.57885747, -50.27186116],\n",
       "       ...,\n",
       "       [-80.        , -80.        , -80.        , ..., -80.        ,\n",
       "        -80.        , -80.        ],\n",
       "       [-80.        , -80.        , -80.        , ..., -80.        ,\n",
       "        -80.        , -80.        ],\n",
       "       [-80.        , -80.        , -80.        , ..., -80.        ,\n",
       "        -80.        , -80.        ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7b40fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_train = np.expand_dims(mel_train, 1) #DataNum, 1ch, H, W\n",
    "x_test = np.expand_dims(mel_test, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "b,c,h,w = x_train.shape\n",
    "x_train = np.reshape(x_train, newshape=(b,-1))\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_train = np.reshape(x_train, newshape=(b,c,h,w))\n",
    "\n",
    "b,c,h,w = x_test.shape\n",
    "x_test = np.reshape(x_test, newshape=(b,-1))\n",
    "x_test = scaler.transform(x_test)\n",
    "x_test = np.reshape(x_test, newshape=(b,c,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "edb9323f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432 1 128 563\n"
     ]
    }
   ],
   "source": [
    "print(b,c,h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8c496e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 563)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "18e2e7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.60112033, -0.30649822,  0.25706405, ...,  1.77106998,\n",
       "          1.74628752,  1.63103596],\n",
       "        [-0.60135263, -0.30401817,  0.24670002, ...,  1.7429967 ,\n",
       "          1.71784582,  1.61426689],\n",
       "        [-0.64321461, -0.08567354,  0.18801808, ...,  1.45738445,\n",
       "          1.43143528,  1.40990592],\n",
       "        ...,\n",
       "        [-0.10187641, -0.08497671, -0.08497671, ..., -0.12079695,\n",
       "         -0.10449628, -0.11001519],\n",
       "        [-0.10180415, -0.08497671, -0.08497671, ..., -0.12073589,\n",
       "         -0.10418719, -0.10975491],\n",
       "        [-0.10175565, -0.08497671, -0.08497671, ..., -0.12069631,\n",
       "         -0.10397835, -0.10958094]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eb23482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Number of trainable params:  101736\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class ParallelModel(nn.Module):\n",
    "    def __init__(self,num_emotions):\n",
    "        super().__init__()\n",
    "       \n",
    "        \n",
    "       # 1. 1stage (Conv + BatchNorm + ReLU + Maxpooling + Dropout)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2,padding=0),\n",
    "            nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Dropout2d(p=0.3)\n",
    "        )\n",
    "                    \n",
    "        \n",
    "        \n",
    "        \n",
    "        # 2. 2stage (Conv + BatchNorm + ReLU + Maxpooling + Dropout)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(4,4), stride=4,padding=0),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Dropout2d(p=0.3)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # 3. 3stage (Conv + BatchNorm + ReLU + Maxpooling + Dropout)\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(4,4), stride=4,padding=0),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Dropout2d(p=0.3)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # 4. 4stage (Conv + BatchNorm + ReLU + Maxpooling + Dropout)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(4,4), stride=4,padding=0),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Dropout2d(p=0.3)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(1*4*128,8,bias=True)\n",
    "        nn.init.orthogonal_(self.fc.weight)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Linear softmax layer\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "    ##Forward\n",
    "        output = self.layer1(x)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = self.layer4(output)\n",
    "        output = output.view(output.size(0),-1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "model = ParallelModel(num_emotions=8).to(device)\n",
    "print('Number of trainable params: ',sum(p.numel() for p in model.parameters()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aff8e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: livelossplot in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (0.5.5)\n",
      "Requirement already satisfied: bokeh in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from livelossplot) (2.4.2)\n",
      "Requirement already satisfied: ipython==7.* in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from livelossplot) (7.26.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from livelossplot) (3.4.2)\n",
      "Requirement already satisfied: numpy<1.22 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from livelossplot) (1.20.3)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from ipython==7.*->livelossplot) (0.7.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from ipython==7.*->livelossplot) (5.0.9)\n",
      "Requirement already satisfied: pygments in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from ipython==7.*->livelossplot) (2.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from ipython==7.*->livelossplot) (0.4.4)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from ipython==7.*->livelossplot) (3.0.17)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from ipython==7.*->livelossplot) (52.0.0.post20210125)\n",
      "Requirement already satisfied: backcall in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from ipython==7.*->livelossplot) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from ipython==7.*->livelossplot) (0.1.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from ipython==7.*->livelossplot) (0.18.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from ipython==7.*->livelossplot) (5.0.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from jedi>=0.16->ipython==7.*->livelossplot) (0.8.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.*->livelossplot) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from traitlets>=4.2->ipython==7.*->livelossplot) (0.2.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from bokeh->livelossplot) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from bokeh->livelossplot) (3.10.0.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from bokeh->livelossplot) (8.3.1)\n",
      "Requirement already satisfied: tornado>=5.1 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from bokeh->livelossplot) (6.1)\n",
      "Requirement already satisfied: packaging>=16.8 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from bokeh->livelossplot) (21.0)\n",
      "Requirement already satisfied: Jinja2>=2.9 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from bokeh->livelossplot) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from packaging>=16.8->bokeh->livelossplot) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from matplotlib->livelossplot) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from matplotlib->livelossplot) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from matplotlib->livelossplot) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\arz61\\miniconda3\\envs\\ml2020\\lib\\site-packages (from cycler>=0.10->matplotlib->livelossplot) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70e58113",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=300\n",
    "DATASET_SIZE = x_train.shape[0]\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "##baseline에서 사용한 optimizer는 SGD이며 하이퍼파라미터는 다음과 같습니다.\n",
    "##Learning rate = 0.01, momentum=0.9\n",
    "OPTIMIZER = torch.optim.SGD(model.parameters(),lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f3977e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fnc(predictions, targets):\n",
    "    return nn.CrossEntropyLoss()(input=predictions,target=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bb8c776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 300/300 [8:50:37<00:00, 106.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\n",
      "\ttrain_loss       \t (min:    0.020, max:    2.239, cur:    0.028)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from livelossplot import PlotLosses\n",
    "from tqdm import trange\n",
    "liveloss = PlotLosses()\n",
    "\n",
    "logs = {}\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "    # shuffle data\n",
    "    ind = np.random.permutation(DATASET_SIZE)\n",
    "\n",
    "    x_train = x_train[ind]\n",
    "    y_train = y_train[ind]\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    iters = int(DATASET_SIZE / BATCH_SIZE)\n",
    "     \n",
    "    for i in range(iters):\n",
    "        ### indexing과정을 통해 작성된 Dataloader 코드\n",
    "        batch_start = i * BATCH_SIZE\n",
    "        batch_end = min(batch_start + BATCH_SIZE, DATASET_SIZE)\n",
    "        actual_batch_size = batch_end-batch_start\n",
    "        \n",
    "        x = x_train[batch_start:batch_end]\n",
    "        y = y_train[batch_start:batch_end]\n",
    "        \n",
    "         ###--------------------작성해야할 부분--------------------------------\n",
    "        ##1.train 데이터를 torch tensor로 타입 변경 및 gpu 설정\n",
    "        X = torch.FloatTensor(x).to(device)\n",
    "        Y = torch.LongTensor(y).to(device)\n",
    "        \n",
    "        ##2.데이터를 모델의 입력으로 넣어 예측 후 loss 계산 및 optimization \n",
    "        model.train()\n",
    "        hypothesis = model(X)\n",
    "        loss = loss_fnc(hypothesis, Y)\n",
    "        \n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        \n",
    "        ###---------------------------------------------------------------\n",
    "        ##1에포크당 평균 loss를 계산하는 코드\n",
    "        epoch_loss += loss.item()*actual_batch_size/DATASET_SIZE\n",
    "\n",
    "    ###liveloss 함수를 사용하기 위한 코드들\n",
    "    logs['train_loss'] = epoch_loss\n",
    "        \n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c2d1c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelModel(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Dropout2d(p=0.3, inplace=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(4, 4), stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Dropout2d(p=0.3, inplace=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(4, 4), stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Dropout2d(p=0.3, inplace=False)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(4, 4), stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Dropout2d(p=0.3, inplace=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37a85bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\arz61\\Documents\\오픈소스'\n",
    "torch.save(model,os.path.join(path,'model_300.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "04216a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.0.weight',\n",
       "              tensor([[[[ 0.1345, -0.0626,  0.0033],\n",
       "                        [ 0.1342, -0.1919,  0.2811],\n",
       "                        [ 0.0614,  0.3187,  0.2362]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2100, -0.0559, -0.2119],\n",
       "                        [-0.0998, -0.3266, -0.2305],\n",
       "                        [-0.4890, -0.3101, -0.3683]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2856,  0.3243,  0.0012],\n",
       "                        [-0.1010,  0.1566, -0.0276],\n",
       "                        [-0.0175,  0.2382,  0.2411]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.4230, -0.4362,  0.1864],\n",
       "                        [ 0.0084,  0.2973,  0.1936],\n",
       "                        [-0.4205, -0.2736, -0.3738]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2208,  0.0640,  0.1141],\n",
       "                        [-0.1179,  0.4691, -0.0960],\n",
       "                        [ 0.2243,  0.1708, -0.1085]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2768, -0.2400,  0.0878],\n",
       "                        [-0.1980, -0.1346, -0.2961],\n",
       "                        [-0.2489,  0.1137, -0.0547]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3352,  0.2531, -0.0313],\n",
       "                        [-0.1437,  0.2124,  0.0976],\n",
       "                        [-0.1356,  0.2004,  0.1413]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.6017, -0.2239, -0.0931],\n",
       "                        [ 0.0212, -0.0733, -0.2834],\n",
       "                        [-0.3814,  0.0171, -0.1017]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1405,  0.0144,  0.2421],\n",
       "                        [ 0.1034,  0.0487,  0.2529],\n",
       "                        [-0.1714,  0.1613, -0.0942]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1221,  0.0363,  0.0085],\n",
       "                        [ 0.3329, -0.0620, -0.1073],\n",
       "                        [ 0.4289,  0.0527,  0.3746]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0278, -0.2226,  0.0150],\n",
       "                        [-0.1079, -0.2490, -0.2378],\n",
       "                        [-0.1102, -0.0339, -0.2855]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0127,  0.3317,  0.0665],\n",
       "                        [ 0.2420,  0.1855, -0.1024],\n",
       "                        [-0.2352,  0.3308,  0.1580]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1414,  0.0548,  0.1247],\n",
       "                        [ 0.1421,  0.2554, -0.2206],\n",
       "                        [-0.0240,  0.1829,  0.2635]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.5419, -0.3641, -0.4511],\n",
       "                        [-0.3563, -0.0176,  0.2590],\n",
       "                        [-0.2525,  0.2909, -0.2406]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3321, -0.1880,  0.1170],\n",
       "                        [ 0.2388, -0.1488,  0.0954],\n",
       "                        [ 0.2092,  0.2251,  0.1481]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2424,  0.3756, -0.1321],\n",
       "                        [-0.3768, -0.3410, -0.2288],\n",
       "                        [-0.2006, -0.2882,  0.0289]]]])),\n",
       "             ('layer1.0.bias',\n",
       "              tensor([-0.0650, -0.1263, -0.1738,  0.3892,  0.1799,  0.0752, -0.3513,  0.3317,\n",
       "                      -0.3361, -0.1072, -0.3342, -0.3132, -0.4291,  0.2531,  0.5630, -0.1448])),\n",
       "             ('layer1.3.weight',\n",
       "              tensor([1.0133, 0.9097, 1.0166, 0.9610, 0.9887, 0.9350, 1.0525, 0.9187, 1.0328,\n",
       "                      1.0222, 0.9598, 1.0133, 1.0294, 0.9939, 0.9935, 1.0014])),\n",
       "             ('layer1.3.bias',\n",
       "              tensor([ 0.0911,  0.1001,  0.0753, -0.2169,  0.0916,  0.0821,  0.2241, -0.2752,\n",
       "                       0.2131,  0.0797,  0.1301,  0.1861,  0.1323, -0.1650, -0.0573,  0.1012])),\n",
       "             ('layer1.3.running_mean',\n",
       "              tensor([0.3842, 0.7061, 0.4008, 0.5691, 0.5249, 0.3200, 0.2805, 0.5309, 0.1888,\n",
       "                      0.3953, 0.2339, 0.3261, 0.2268, 0.4667, 0.7143, 0.2647])),\n",
       "             ('layer1.3.running_var',\n",
       "              tensor([0.4628, 0.8172, 0.5744, 0.1128, 0.6101, 0.1079, 0.3576, 0.1373, 0.1845,\n",
       "                      0.5028, 0.1638, 0.4411, 0.2843, 0.1276, 0.1956, 0.1400])),\n",
       "             ('layer1.3.num_batches_tracked', tensor(4502)),\n",
       "             ('layer2.0.weight',\n",
       "              tensor([[[[-3.3232e-02,  9.7295e-02,  6.9090e-02],\n",
       "                        [ 8.3321e-02, -3.0273e-03,  6.4041e-02],\n",
       "                        [ 5.0125e-03,  3.0091e-02, -2.9563e-02]],\n",
       "              \n",
       "                       [[-4.3089e-02, -7.7958e-02, -3.9022e-03],\n",
       "                        [-1.0277e-03, -2.1513e-02,  4.3445e-02],\n",
       "                        [ 5.3862e-02, -7.3650e-03, -4.7695e-02]],\n",
       "              \n",
       "                       [[-1.5105e-02,  1.0355e-01,  2.6669e-02],\n",
       "                        [ 4.6689e-02, -1.7745e-02,  2.8560e-02],\n",
       "                        [ 8.9354e-03,  1.3713e-01, -5.8178e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.6229e-02, -1.1532e-02,  1.6766e-02],\n",
       "                        [-5.3927e-02,  2.7986e-02,  1.4399e-02],\n",
       "                        [ 3.1122e-02, -9.3492e-02, -6.6358e-02]],\n",
       "              \n",
       "                       [[-3.1728e-02,  1.2250e-01,  1.2974e-02],\n",
       "                        [ 3.1929e-02,  3.7998e-02, -1.0862e-02],\n",
       "                        [ 1.1991e-01,  1.2980e-01,  5.5529e-02]],\n",
       "              \n",
       "                       [[-1.0926e-02, -7.9503e-02, -3.6805e-02],\n",
       "                        [-1.3413e-02, -6.8092e-02, -3.1501e-02],\n",
       "                        [-7.2111e-03,  9.0289e-03, -9.7579e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3600e-02, -5.9755e-02, -1.4272e-01],\n",
       "                        [ 1.5814e-01, -5.4766e-03,  3.5132e-02],\n",
       "                        [ 4.8381e-02, -4.7228e-02, -9.9104e-02]],\n",
       "              \n",
       "                       [[-5.2542e-02,  6.6505e-02,  1.5055e-02],\n",
       "                        [-6.6504e-02,  3.8573e-02,  1.4369e-01],\n",
       "                        [-1.6913e-02, -7.3224e-02,  2.0431e-02]],\n",
       "              \n",
       "                       [[ 4.9256e-02, -1.0300e-04, -5.7560e-04],\n",
       "                        [ 3.0231e-02, -1.2728e-02, -7.1527e-03],\n",
       "                        [-9.9514e-03, -3.0337e-03,  2.0390e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.2926e-01,  3.9986e-02,  2.8434e-02],\n",
       "                        [ 1.1999e-01,  1.2933e-01, -6.9837e-02],\n",
       "                        [-6.7888e-02,  7.6242e-03, -3.3490e-02]],\n",
       "              \n",
       "                       [[ 4.0152e-02, -3.0132e-02, -3.9278e-02],\n",
       "                        [ 1.1720e-01,  3.5559e-02, -1.2986e-01],\n",
       "                        [ 5.9444e-02, -3.7697e-02,  1.7358e-02]],\n",
       "              \n",
       "                       [[-2.5507e-02, -3.3697e-01, -1.5601e-02],\n",
       "                        [-1.1386e-01,  2.0098e-01,  5.5780e-02],\n",
       "                        [ 2.2288e-01,  2.3497e-02,  8.3719e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2834e-01, -1.1934e-01, -1.0217e-01],\n",
       "                        [-4.1127e-02,  1.0992e-01, -3.0746e-02],\n",
       "                        [ 7.7864e-02,  1.1470e-01, -1.1238e-01]],\n",
       "              \n",
       "                       [[ 2.3929e-03,  2.5358e-02, -6.3614e-03],\n",
       "                        [ 9.3009e-02, -1.7911e-01,  6.7131e-02],\n",
       "                        [ 2.4552e-02, -1.1444e-01,  1.2034e-02]],\n",
       "              \n",
       "                       [[-1.1105e-01, -1.0522e-01, -1.5243e-01],\n",
       "                        [-7.8169e-02, -7.0106e-03, -8.0994e-02],\n",
       "                        [ 1.3555e-01,  1.6491e-01,  1.5205e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3653e-01,  5.4275e-02,  1.6292e-02],\n",
       "                        [ 2.1743e-02,  2.6631e-02,  1.0037e-01],\n",
       "                        [ 3.2654e-02, -1.0714e-01, -1.5416e-01]],\n",
       "              \n",
       "                       [[-8.4504e-02, -1.7151e-02,  2.2351e-02],\n",
       "                        [ 1.0923e-02,  8.4618e-02, -1.0381e-02],\n",
       "                        [ 9.1575e-02,  5.6425e-02, -1.2499e-01]],\n",
       "              \n",
       "                       [[ 1.1225e-01, -3.6483e-02, -5.8540e-02],\n",
       "                        [-2.8524e-02, -2.3145e-02, -1.4928e-02],\n",
       "                        [ 3.4007e-02, -1.1722e-01, -1.4040e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.0959e-01, -8.1700e-02, -1.2808e-01],\n",
       "                        [-9.3419e-02,  3.0975e-02, -6.5585e-02],\n",
       "                        [-7.4978e-03,  1.7191e-01,  7.9126e-02]],\n",
       "              \n",
       "                       [[-2.3254e-03,  2.4779e-02,  1.2680e-01],\n",
       "                        [-8.0721e-03,  8.3290e-02,  1.1482e-02],\n",
       "                        [-1.9700e-01, -6.9699e-02, -1.1274e-01]],\n",
       "              \n",
       "                       [[ 6.3497e-02, -3.4577e-02, -8.0462e-02],\n",
       "                        [ 4.8755e-02, -1.0428e-01, -2.7941e-02],\n",
       "                        [ 1.8933e-02, -6.8632e-02, -8.5412e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.1904e-02,  6.6752e-02,  2.9530e-01],\n",
       "                        [-9.2299e-02, -1.8168e-02,  2.8412e-02],\n",
       "                        [-7.4759e-02,  5.8989e-02,  1.2112e-02]],\n",
       "              \n",
       "                       [[-5.3392e-02, -9.3453e-02, -1.0791e-01],\n",
       "                        [-1.0900e-02, -4.3898e-02, -6.4905e-02],\n",
       "                        [ 5.5023e-03,  1.3883e-01,  1.8029e-01]],\n",
       "              \n",
       "                       [[ 7.8530e-03,  9.1271e-02,  1.5828e-01],\n",
       "                        [-6.0665e-02,  4.0514e-02, -2.3514e-02],\n",
       "                        [-1.3919e-01, -1.0135e-02, -1.3507e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7905e-03,  8.1730e-02, -4.6954e-03],\n",
       "                        [ 5.7172e-02,  3.2160e-03,  8.0313e-02],\n",
       "                        [-1.9242e-02,  3.7120e-02,  5.7962e-02]],\n",
       "              \n",
       "                       [[ 2.6489e-02,  1.6548e-02, -4.5911e-02],\n",
       "                        [ 2.0988e-02, -8.8300e-02, -4.1532e-02],\n",
       "                        [ 3.2711e-03, -8.1679e-02, -4.1844e-02]],\n",
       "              \n",
       "                       [[ 5.9037e-02, -2.9592e-02,  5.4409e-02],\n",
       "                        [-1.6118e-02, -7.5267e-03,  5.3529e-02],\n",
       "                        [-8.5487e-03,  3.4582e-02,  8.9146e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.9282e-02,  4.4628e-02,  3.6784e-03],\n",
       "                        [-3.3594e-02, -1.4290e-01, -6.5963e-02],\n",
       "                        [ 1.0851e-02,  2.6690e-02,  1.6726e-02]],\n",
       "              \n",
       "                       [[ 4.1337e-02,  8.3619e-02,  6.7950e-02],\n",
       "                        [ 3.8371e-02,  7.1030e-02, -1.1445e-02],\n",
       "                        [ 6.9470e-02,  7.8710e-02, -6.1109e-02]],\n",
       "              \n",
       "                       [[-8.2597e-02, -7.0207e-03,  4.6653e-02],\n",
       "                        [-4.7424e-02, -3.0324e-02,  2.9433e-02],\n",
       "                        [-7.1593e-02, -4.4632e-02,  8.2791e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.8059e-04,  5.7753e-02,  3.8762e-02],\n",
       "                        [ 8.0076e-03,  1.0124e-01,  8.0302e-02],\n",
       "                        [-1.1642e-01, -2.5717e-03, -2.6815e-02]],\n",
       "              \n",
       "                       [[-9.5414e-03, -7.6547e-02, -4.4201e-02],\n",
       "                        [-4.1740e-02,  3.8138e-03, -3.5602e-03],\n",
       "                        [ 6.7172e-02, -5.4975e-02, -6.1587e-02]],\n",
       "              \n",
       "                       [[ 6.6182e-02,  9.2763e-02,  7.2361e-02],\n",
       "                        [-1.0270e-01,  6.1981e-02,  2.8332e-02],\n",
       "                        [-1.5583e-01, -9.4751e-02, -1.3030e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0205e-02, -9.0267e-02,  5.0323e-02],\n",
       "                        [-4.9866e-02,  8.8068e-02, -9.4564e-02],\n",
       "                        [ 6.5720e-02, -2.1824e-02,  9.0214e-02]],\n",
       "              \n",
       "                       [[ 1.4063e-01,  1.2890e-01, -2.0182e-03],\n",
       "                        [-3.4575e-02, -2.4142e-02, -6.4851e-03],\n",
       "                        [ 2.6264e-02,  5.8175e-02, -3.8201e-02]],\n",
       "              \n",
       "                       [[ 3.9445e-02, -5.1593e-02, -6.1897e-02],\n",
       "                        [-6.7188e-02, -1.2202e-02, -4.0830e-02],\n",
       "                        [ 6.4973e-02, -3.3398e-03, -3.0440e-02]]]])),\n",
       "             ('layer2.0.bias',\n",
       "              tensor([ 0.0463,  0.0361,  0.0726,  0.1248,  0.0434,  0.0650, -0.0483,  0.0126,\n",
       "                       0.0469,  0.0955,  0.0773, -0.0826,  0.1406, -0.0094,  0.0956,  0.2549,\n",
       "                       0.1465, -0.0162,  0.1167,  0.0776,  0.0614,  0.0537, -0.0435,  0.0850,\n",
       "                       0.0700,  0.0346,  0.0646,  0.1001,  0.1271,  0.0929, -0.0190,  0.0801])),\n",
       "             ('layer2.3.weight',\n",
       "              tensor([1.0995, 0.9489, 0.9933, 0.9580, 0.9105, 1.0154, 0.9520, 0.9726, 0.9369,\n",
       "                      0.9340, 0.9557, 1.0588, 0.9413, 0.9545, 0.9735, 0.9131, 0.9156, 1.0282,\n",
       "                      0.9285, 0.8790, 0.9561, 1.0224, 1.0227, 0.9411, 0.9635, 0.8850, 1.0338,\n",
       "                      0.9366, 0.9389, 0.9261, 1.0468, 0.9931])),\n",
       "             ('layer2.3.bias',\n",
       "              tensor([0.3637, 0.2293, 0.3621, 0.1280, 0.2082, 0.2154, 0.1715, 0.2635, 0.2787,\n",
       "                      0.2811, 0.3408, 0.2844, 0.0420, 0.2965, 0.3384, 0.1953, 0.3473, 0.2524,\n",
       "                      0.1987, 0.2571, 0.1339, 0.2648, 0.3011, 0.2773, 0.2200, 0.2565, 0.2687,\n",
       "                      0.2600, 0.1876, 0.1241, 0.3451, 0.2577])),\n",
       "             ('layer2.3.running_mean',\n",
       "              tensor([2.1088, 0.9405, 1.3103, 1.2315, 1.7951, 1.8033, 1.2870, 1.5456, 1.3509,\n",
       "                      1.2342, 1.6620, 1.7968, 1.7051, 1.5435, 1.5283, 1.9066, 1.6746, 2.1191,\n",
       "                      1.4719, 1.5321, 2.1294, 2.3741, 1.8273, 1.4715, 1.4300, 1.0991, 1.7523,\n",
       "                      1.4666, 1.3490, 1.3835, 2.0189, 1.3913])),\n",
       "             ('layer2.3.running_var',\n",
       "              tensor([10.8964,  1.1330,  1.4125,  1.7356,  7.6284,  6.4955,  1.9727,  5.3341,\n",
       "                       2.3699,  1.5495,  2.3266,  7.7488,  1.2607,  3.9283,  3.1566,  1.7776,\n",
       "                       2.0113,  8.6749,  1.1139,  1.6001,  6.9745, 13.1653,  6.3463,  1.6293,\n",
       "                       3.4505,  0.7719,  7.7579,  1.7112,  0.9068,  1.2049,  9.2682,  3.0040])),\n",
       "             ('layer2.3.num_batches_tracked', tensor(4502)),\n",
       "             ('layer3.0.weight',\n",
       "              tensor([[[[ 5.9540e-02, -2.6352e-02, -1.4848e-02],\n",
       "                        [-8.7963e-02, -7.5860e-02, -4.6368e-02],\n",
       "                        [-3.2498e-02, -1.3881e-02,  3.1931e-02]],\n",
       "              \n",
       "                       [[ 3.4142e-02, -1.6746e-02, -5.5384e-02],\n",
       "                        [ 4.3807e-02, -1.4036e-02, -3.4147e-02],\n",
       "                        [ 7.6012e-02,  3.2691e-02, -4.8154e-03]],\n",
       "              \n",
       "                       [[-3.8268e-02, -7.4789e-02,  1.0864e-03],\n",
       "                        [-5.0149e-02,  1.2638e-02,  5.0440e-02],\n",
       "                        [-7.9562e-03,  3.1624e-02, -1.1176e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.8977e-02,  1.4684e-02, -5.7627e-02],\n",
       "                        [-2.1039e-02, -3.4329e-02,  2.1319e-02],\n",
       "                        [ 1.1600e-01,  5.3487e-02,  1.1628e-02]],\n",
       "              \n",
       "                       [[ 8.9917e-02, -3.9263e-02, -1.7836e-02],\n",
       "                        [-8.2857e-02, -5.5777e-02,  4.4320e-02],\n",
       "                        [-7.7343e-03, -1.0394e-01,  1.9313e-02]],\n",
       "              \n",
       "                       [[ 3.4723e-02,  2.8965e-02,  8.4072e-02],\n",
       "                        [-3.4475e-05, -5.4937e-02, -9.2427e-02],\n",
       "                        [-5.2921e-02, -6.8067e-02,  2.4393e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3041e-01, -8.8356e-02,  3.4634e-03],\n",
       "                        [ 5.9397e-02,  5.7382e-02,  4.9824e-02],\n",
       "                        [-4.0777e-02, -1.1341e-02,  1.7965e-02]],\n",
       "              \n",
       "                       [[-9.7395e-03, -7.1848e-02, -5.1242e-02],\n",
       "                        [-1.2291e-01, -5.7350e-02, -6.0430e-02],\n",
       "                        [-1.6208e-01, -1.4128e-01, -3.7633e-02]],\n",
       "              \n",
       "                       [[-7.6209e-02, -9.1071e-02, -5.1919e-02],\n",
       "                        [ 6.0357e-02,  5.6995e-02,  2.8818e-03],\n",
       "                        [ 4.9936e-02,  7.3311e-02,  3.6977e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.7080e-03,  2.8273e-03, -1.7874e-02],\n",
       "                        [-2.5508e-03, -7.3983e-03, -4.7679e-02],\n",
       "                        [-8.9153e-02, -7.1558e-02,  4.2720e-02]],\n",
       "              \n",
       "                       [[-1.1322e-01, -7.3636e-02, -6.3403e-02],\n",
       "                        [ 5.8245e-02,  7.0846e-02,  2.2516e-03],\n",
       "                        [-4.2180e-02,  1.9472e-02,  1.2216e-02]],\n",
       "              \n",
       "                       [[-5.6739e-02, -3.5917e-02,  4.8673e-03],\n",
       "                        [ 8.3786e-03, -7.3501e-03,  2.6109e-02],\n",
       "                        [ 6.1202e-02,  2.6466e-02, -4.9719e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.7044e-03,  7.0969e-02, -4.5075e-02],\n",
       "                        [-8.0812e-02,  5.0159e-02, -4.9265e-02],\n",
       "                        [-3.7662e-02,  7.9466e-02, -4.5544e-02]],\n",
       "              \n",
       "                       [[-6.6546e-02,  3.4601e-03,  3.1612e-02],\n",
       "                        [ 1.6953e-02, -9.7890e-03, -1.2187e-02],\n",
       "                        [ 4.1405e-02,  8.1795e-02, -2.5738e-02]],\n",
       "              \n",
       "                       [[ 2.3039e-02,  7.1450e-02,  6.2239e-02],\n",
       "                        [-5.7117e-02, -1.3065e-02, -4.6584e-02],\n",
       "                        [ 1.6822e-02,  2.4173e-02, -6.7851e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.4037e-02, -1.5375e-02, -1.0165e-02],\n",
       "                        [-7.5659e-02,  8.4561e-03,  8.6083e-03],\n",
       "                        [-3.6973e-02, -2.8500e-02, -8.0843e-02]],\n",
       "              \n",
       "                       [[-1.6243e-02, -4.3270e-03, -1.3728e-02],\n",
       "                        [ 1.3072e-03,  4.8098e-02, -3.8287e-02],\n",
       "                        [-7.4106e-02,  8.9815e-02, -9.8975e-02]],\n",
       "              \n",
       "                       [[ 1.2142e-02,  6.8367e-02, -8.4503e-02],\n",
       "                        [-4.4703e-02, -1.8237e-02,  5.8011e-03],\n",
       "                        [ 6.4639e-02,  3.3783e-02,  1.4411e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.1507e-02, -4.0333e-02, -8.4225e-02],\n",
       "                        [ 5.8791e-02,  1.2726e-02, -1.9517e-02],\n",
       "                        [ 2.1269e-02,  5.9941e-02, -3.2166e-02]],\n",
       "              \n",
       "                       [[-7.6149e-03,  9.0534e-02, -1.0668e-02],\n",
       "                        [ 4.1567e-02,  5.3300e-02, -4.8391e-02],\n",
       "                        [ 3.6176e-02,  1.1110e-01, -9.2725e-02]],\n",
       "              \n",
       "                       [[-1.6174e-02,  1.1475e-02, -7.3024e-02],\n",
       "                        [ 1.5947e-02, -3.6369e-02, -4.6841e-02],\n",
       "                        [-6.3680e-02,  6.8842e-02,  4.8663e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3737e-02, -4.4671e-03, -1.3201e-02],\n",
       "                        [ 2.0922e-02,  1.8939e-02, -8.7681e-02],\n",
       "                        [-1.1772e-02,  2.2877e-02, -1.3123e-01]],\n",
       "              \n",
       "                       [[ 8.1478e-02, -1.8309e-02, -6.2735e-03],\n",
       "                        [-1.6753e-02, -1.7301e-02, -5.0031e-02],\n",
       "                        [ 8.1102e-02,  6.1124e-02, -2.7700e-02]],\n",
       "              \n",
       "                       [[ 1.4709e-02,  7.6381e-03, -8.3370e-02],\n",
       "                        [ 1.4060e-02,  2.2350e-02, -1.3798e-01],\n",
       "                        [ 5.2885e-02,  1.1016e-01, -3.3605e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.0549e-03, -2.6861e-02, -8.0906e-02],\n",
       "                        [ 1.1694e-01, -2.9956e-02, -6.6291e-02],\n",
       "                        [ 1.2079e-02, -1.4518e-01, -5.4865e-02]],\n",
       "              \n",
       "                       [[ 3.2613e-03, -2.5226e-02,  5.8625e-02],\n",
       "                        [ 3.5233e-02,  4.7141e-02,  5.6739e-02],\n",
       "                        [ 9.4537e-02, -2.4141e-02, -4.2203e-02]],\n",
       "              \n",
       "                       [[ 9.4774e-02, -1.1773e-01, -4.6859e-02],\n",
       "                        [ 7.2792e-02, -2.7433e-02, -6.3899e-02],\n",
       "                        [ 5.0998e-02, -1.7140e-02, -4.6873e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.8275e-02,  5.3605e-02, -5.4252e-02],\n",
       "                        [ 2.2147e-02, -6.6531e-02, -3.6803e-02],\n",
       "                        [ 5.0612e-04, -1.7190e-02,  6.0150e-02]],\n",
       "              \n",
       "                       [[-1.0671e-02, -1.0203e-01, -2.0740e-02],\n",
       "                        [ 2.6049e-02, -7.5276e-02,  1.5577e-02],\n",
       "                        [ 5.2760e-02, -9.9515e-02, -3.9306e-02]],\n",
       "              \n",
       "                       [[ 2.8230e-02, -5.3273e-02, -4.7167e-02],\n",
       "                        [ 8.7781e-02, -8.7317e-02, -5.5988e-02],\n",
       "                        [ 1.9106e-02, -5.0670e-02, -4.4421e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.4715e-02, -4.1895e-02, -2.3911e-02],\n",
       "                        [ 2.4342e-02, -1.0329e-01, -5.2100e-02],\n",
       "                        [-1.2532e-02, -9.6558e-02, -3.3466e-02]],\n",
       "              \n",
       "                       [[ 1.8578e-02,  2.7393e-02, -5.0196e-03],\n",
       "                        [ 3.2364e-02, -5.0100e-02,  6.4497e-02],\n",
       "                        [ 1.2441e-01, -8.1842e-02, -5.8147e-02]],\n",
       "              \n",
       "                       [[-2.8352e-02, -1.3112e-01, -1.2713e-01],\n",
       "                        [ 6.0155e-02, -1.5521e-01, -8.4025e-02],\n",
       "                        [ 1.1725e-01, -1.1683e-01,  4.4932e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.7187e-02, -9.6186e-02, -8.8688e-02],\n",
       "                        [ 8.6457e-02, -8.7098e-02, -7.8273e-02],\n",
       "                        [ 1.2287e-01, -2.8412e-02,  3.8477e-02]],\n",
       "              \n",
       "                       [[ 3.2807e-02, -9.8369e-02, -6.8239e-02],\n",
       "                        [ 4.9923e-02, -5.6533e-02, -5.3858e-02],\n",
       "                        [ 2.3828e-03, -2.9734e-02, -5.4040e-02]],\n",
       "              \n",
       "                       [[ 3.8913e-02, -6.1936e-02,  3.8440e-02],\n",
       "                        [ 5.0650e-02, -7.8688e-02,  2.0638e-02],\n",
       "                        [ 4.9567e-02, -5.0903e-02, -4.8019e-02]]]])),\n",
       "             ('layer3.0.bias',\n",
       "              tensor([ 0.0503,  0.0127, -0.1846, -0.0220,  0.0118, -0.0681, -0.0479, -0.0653,\n",
       "                      -0.0353, -0.0444, -0.0357, -0.0549,  0.0148,  0.0245,  0.0210, -0.0523,\n",
       "                      -0.0192,  0.0417,  0.0047, -0.0446,  0.0038,  0.0289, -0.0505, -0.0033,\n",
       "                       0.0171, -0.0494,  0.0233, -0.0048,  0.0302,  0.0594, -0.0946, -0.0399,\n",
       "                       0.0056,  0.0122,  0.0193,  0.0011, -0.1100, -0.0154, -0.0187, -0.0321,\n",
       "                      -0.0121, -0.0985,  0.0277,  0.0169,  0.0495, -0.0628, -0.1452, -0.0938,\n",
       "                      -0.0703, -0.0632, -0.0195,  0.0053, -0.0400, -0.1027, -0.0631, -0.0548,\n",
       "                      -0.1058, -0.0808,  0.0391, -0.0195, -0.0313, -0.0249,  0.0145,  0.0307])),\n",
       "             ('layer3.3.weight',\n",
       "              tensor([0.9540, 0.9561, 0.9985, 1.0201, 0.9893, 1.0617, 0.9211, 0.9149, 1.0456,\n",
       "                      0.9081, 1.0613, 1.0691, 1.0120, 1.0470, 1.0748, 1.0232, 1.0141, 1.0463,\n",
       "                      0.9080, 1.1188, 1.0056, 0.9732, 1.0697, 0.9350, 0.9326, 0.9955, 1.0144,\n",
       "                      0.9575, 1.0428, 1.0884, 0.9989, 1.0066, 0.9368, 0.9577, 0.9879, 1.1240,\n",
       "                      0.9875, 1.0374, 1.0654, 0.9863, 1.0052, 0.9538, 1.0431, 0.9883, 0.9256,\n",
       "                      0.9474, 1.0467, 0.9625, 0.9031, 1.0799, 0.9461, 0.9866, 0.9597, 1.0066,\n",
       "                      0.9484, 0.9873, 0.9570, 0.9605, 0.9881, 1.1055, 1.0386, 0.9706, 0.9428,\n",
       "                      0.9904])),\n",
       "             ('layer3.3.bias',\n",
       "              tensor([ 0.1083,  0.0076,  0.0669,  0.0025,  0.0560, -0.0392,  0.1003,  0.0273,\n",
       "                       0.0819,  0.0311, -0.0052,  0.0948,  0.0369,  0.1552, -0.0418,  0.0735,\n",
       "                       0.1093,  0.1400, -0.0427, -0.0305,  0.0309, -0.0925,  0.0681,  0.1200,\n",
       "                       0.0777, -0.0273,  0.0283, -0.0015,  0.0895, -0.0323,  0.0570, -0.0449,\n",
       "                       0.0798,  0.0386,  0.0464, -0.0503,  0.0664,  0.1101,  0.0988,  0.1010,\n",
       "                       0.0746,  0.0504,  0.0942,  0.0952,  0.0534,  0.0655,  0.1362,  0.0074,\n",
       "                       0.0759,  0.1070,  0.0346, -0.0271,  0.0866,  0.0903,  0.0965,  0.0942,\n",
       "                       0.0686,  0.0814,  0.1258,  0.0414,  0.1534,  0.0282,  0.1017,  0.0974])),\n",
       "             ('layer3.3.running_mean',\n",
       "              tensor([2.3685, 1.7127, 1.6659, 2.2055, 2.1331, 1.8426, 2.1032, 2.4761, 2.2788,\n",
       "                      1.3065, 2.0598, 2.4135, 2.2098, 2.2849, 2.0213, 1.8579, 2.0315, 2.2163,\n",
       "                      2.0308, 1.7288, 2.1006, 1.3953, 2.4706, 2.2167, 2.3894, 1.6648, 2.2255,\n",
       "                      2.3505, 2.1193, 2.2719, 2.3828, 2.2442, 1.9244, 1.9875, 1.8329, 2.1216,\n",
       "                      1.6409, 1.6516, 2.0215, 2.0169, 1.5630, 1.6391, 2.6781, 1.8908, 1.8954,\n",
       "                      1.7957, 2.0805, 1.8359, 1.8115, 1.9721, 2.6723, 1.8266, 2.1505, 1.6706,\n",
       "                      1.8812, 2.0618, 1.7549, 2.3489, 2.1744, 2.3216, 2.4377, 2.1973, 2.0975,\n",
       "                      1.8691])),\n",
       "             ('layer3.3.running_var',\n",
       "              tensor([3.2817, 2.0292, 3.2088, 2.0915, 3.4443, 2.6634, 2.7279, 3.6755, 2.5261,\n",
       "                      1.5318, 2.8184, 3.3522, 2.7452, 2.5196, 2.4656, 2.2592, 2.7503, 2.6861,\n",
       "                      3.4677, 1.7542, 2.1355, 1.8109, 3.4520, 3.6306, 4.6758, 2.0469, 2.6616,\n",
       "                      3.2089, 2.8848, 3.0045, 7.7535, 3.7217, 2.8153, 2.1650, 1.7515, 2.6612,\n",
       "                      2.1498, 3.4030, 2.2470, 5.9068, 1.6009, 2.6886, 3.1612, 1.9838, 2.1136,\n",
       "                      2.3383, 2.8542, 2.3813, 2.9540, 1.9065, 4.1751, 2.2663, 2.4741, 2.4299,\n",
       "                      6.3036, 2.7760, 4.1385, 5.4730, 2.6161, 2.8068, 5.9188, 4.0899, 2.8170,\n",
       "                      2.7023])),\n",
       "             ('layer3.3.num_batches_tracked', tensor(4502)),\n",
       "             ('layer4.0.weight',\n",
       "              tensor([[[[-1.0213e-02, -4.9385e-02,  3.3545e-02],\n",
       "                        [ 4.1768e-02, -4.5182e-02,  2.8292e-03],\n",
       "                        [-4.4821e-02, -3.8773e-03,  9.7159e-03]],\n",
       "              \n",
       "                       [[-1.8232e-02,  3.8045e-02,  1.2049e-01],\n",
       "                        [ 1.1481e-02,  1.7003e-02,  2.3145e-02],\n",
       "                        [ 6.6521e-02, -2.8518e-02,  1.1295e-02]],\n",
       "              \n",
       "                       [[-3.2815e-02,  2.0487e-03,  1.3759e-03],\n",
       "                        [-6.9526e-02, -4.3463e-03, -2.4011e-02],\n",
       "                        [-9.8167e-02,  1.2673e-03, -5.6190e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.0059e-02,  6.6412e-02, -3.1126e-02],\n",
       "                        [-2.3497e-02, -2.8327e-02, -5.6830e-02],\n",
       "                        [-6.8407e-02, -9.5902e-02,  3.7917e-02]],\n",
       "              \n",
       "                       [[ 8.6022e-04,  1.5170e-02,  6.3552e-02],\n",
       "                        [ 5.6443e-02, -4.1845e-02, -1.9360e-02],\n",
       "                        [-3.6416e-02, -8.4007e-02,  1.4845e-01]],\n",
       "              \n",
       "                       [[-2.6549e-02,  5.3032e-02,  5.0383e-02],\n",
       "                        [-1.8563e-02, -6.8408e-02, -5.2456e-02],\n",
       "                        [ 2.1483e-02, -9.8491e-02,  1.8709e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8119e-02, -2.3159e-02, -3.1780e-02],\n",
       "                        [-3.5852e-02, -2.1555e-02, -1.0112e-01],\n",
       "                        [ 1.9325e-02, -2.0901e-02,  3.0849e-02]],\n",
       "              \n",
       "                       [[-4.8231e-02,  6.0060e-02, -5.2302e-03],\n",
       "                        [ 7.0584e-02, -3.8350e-02,  9.8568e-02],\n",
       "                        [ 3.1392e-02, -1.0719e-01, -2.8838e-02]],\n",
       "              \n",
       "                       [[-6.1594e-02,  1.5957e-02, -3.5148e-02],\n",
       "                        [ 9.1852e-03,  8.4300e-02,  3.7336e-02],\n",
       "                        [-4.8866e-02, -1.4064e-02, -3.5838e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.3873e-02, -2.6014e-03, -5.3786e-02],\n",
       "                        [-8.0688e-03, -3.3996e-02, -1.4563e-02],\n",
       "                        [-1.2042e-01,  2.3454e-02, -4.3136e-02]],\n",
       "              \n",
       "                       [[-2.5776e-02, -2.3401e-02, -6.1362e-02],\n",
       "                        [-9.4805e-02, -3.0320e-02, -9.4300e-02],\n",
       "                        [-1.1544e-01,  3.3214e-02,  4.2884e-02]],\n",
       "              \n",
       "                       [[-9.1734e-03, -1.6307e-02, -3.0352e-03],\n",
       "                        [-4.1965e-02, -6.6889e-02, -5.6564e-02],\n",
       "                        [-5.7605e-02,  6.4438e-03,  2.4348e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.1425e-02,  3.5511e-02,  2.2509e-02],\n",
       "                        [-5.8998e-02, -1.0461e-02, -4.4150e-03],\n",
       "                        [-3.2307e-02,  1.0405e-01, -6.0620e-02]],\n",
       "              \n",
       "                       [[ 5.2683e-02, -2.5981e-02,  1.6241e-02],\n",
       "                        [ 6.8121e-02,  4.2590e-03,  7.4070e-03],\n",
       "                        [-4.4108e-02,  2.7215e-02, -6.3510e-02]],\n",
       "              \n",
       "                       [[ 7.8694e-03,  2.8441e-04, -4.3532e-03],\n",
       "                        [-8.8447e-03, -5.3362e-03,  5.4583e-03],\n",
       "                        [ 1.2400e-02, -3.2573e-02,  2.0567e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.9610e-02, -1.2505e-02,  3.3337e-02],\n",
       "                        [-4.6444e-02, -2.1079e-02,  1.6906e-02],\n",
       "                        [ 1.3438e-02, -3.0584e-02, -3.1810e-02]],\n",
       "              \n",
       "                       [[-4.8964e-02, -5.2601e-02, -1.6822e-02],\n",
       "                        [-5.1059e-02, -3.9442e-02, -8.2245e-02],\n",
       "                        [-7.7936e-03,  1.1412e-02, -4.1079e-02]],\n",
       "              \n",
       "                       [[ 4.8652e-02,  3.9467e-02,  4.2700e-02],\n",
       "                        [-5.6255e-02, -6.5913e-02, -1.8364e-03],\n",
       "                        [-5.7568e-02,  1.0844e-01, -3.5888e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.4594e-01, -8.4482e-02, -4.7904e-02],\n",
       "                        [-2.5807e-02, -6.5461e-02,  1.1408e-01],\n",
       "                        [ 4.1496e-02, -1.9970e-02,  7.5592e-02]],\n",
       "              \n",
       "                       [[ 3.5456e-02,  3.4336e-02,  6.0462e-02],\n",
       "                        [ 4.0283e-02,  5.4178e-02, -1.1553e-02],\n",
       "                        [-4.4229e-02, -7.3748e-02,  1.6868e-02]],\n",
       "              \n",
       "                       [[ 6.5665e-02,  1.5805e-02, -1.5345e-02],\n",
       "                        [ 6.5131e-02, -5.4491e-02,  3.8878e-03],\n",
       "                        [-1.1006e-01,  4.9448e-02, -8.1181e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.4306e-03,  1.4148e-02,  3.0137e-03],\n",
       "                        [-6.3876e-02, -4.8362e-02, -1.3653e-02],\n",
       "                        [-1.3454e-02, -2.4289e-02, -3.9694e-02]],\n",
       "              \n",
       "                       [[-1.1767e-01, -5.2954e-02, -5.4189e-02],\n",
       "                        [-7.7011e-02, -1.5229e-02,  7.1363e-03],\n",
       "                        [ 4.2984e-02, -2.4017e-02,  1.4937e-02]],\n",
       "              \n",
       "                       [[-4.3301e-02,  5.6790e-02, -6.6263e-02],\n",
       "                        [-6.6334e-02, -4.2808e-02, -4.1628e-02],\n",
       "                        [ 1.3013e-01,  3.9844e-03,  3.5124e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3681e-02,  6.1994e-03, -1.4970e-02],\n",
       "                        [-3.7163e-02, -6.9807e-02,  3.3613e-02],\n",
       "                        [ 2.9312e-02, -5.2011e-02,  9.4104e-02]],\n",
       "              \n",
       "                       [[-3.3879e-02, -5.3358e-02,  3.2425e-02],\n",
       "                        [ 2.7851e-02, -3.2306e-03, -1.2346e-02],\n",
       "                        [ 3.3795e-02,  2.3680e-03, -2.4819e-02]],\n",
       "              \n",
       "                       [[ 1.1566e-02,  5.7807e-03, -7.9380e-03],\n",
       "                        [-3.4556e-04, -3.6847e-02, -8.6999e-02],\n",
       "                        [-4.0808e-02, -6.2715e-02,  2.3027e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5858e-02,  8.1811e-03,  5.4155e-03],\n",
       "                        [ 9.7834e-03, -6.5303e-02, -4.8361e-03],\n",
       "                        [ 2.8207e-02,  1.1735e-04, -6.6269e-02]],\n",
       "              \n",
       "                       [[ 9.2667e-02, -9.8043e-02, -9.5403e-02],\n",
       "                        [ 3.6479e-02, -7.7189e-02, -4.5646e-02],\n",
       "                        [ 1.4829e-02, -3.1473e-02,  6.3008e-02]],\n",
       "              \n",
       "                       [[ 9.5400e-02, -6.0649e-02, -4.0726e-02],\n",
       "                        [ 8.7807e-02,  4.3226e-03, -8.6181e-02],\n",
       "                        [ 9.9203e-02, -3.9932e-02, -1.0609e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9205e-03,  5.3722e-03, -4.3128e-03],\n",
       "                        [-3.3159e-02, -3.4865e-02, -4.0232e-02],\n",
       "                        [-6.2985e-02,  4.6477e-02, -7.2675e-03]],\n",
       "              \n",
       "                       [[-1.9255e-03, -3.2082e-02,  6.3077e-02],\n",
       "                        [-2.7356e-02,  4.3918e-02,  1.0684e-02],\n",
       "                        [ 6.1463e-03, -3.0764e-02, -5.3252e-02]],\n",
       "              \n",
       "                       [[ 2.5392e-02, -3.1043e-02, -7.6383e-04],\n",
       "                        [-3.7101e-03, -6.5703e-03, -6.5120e-02],\n",
       "                        [-5.7682e-02,  6.8170e-03, -4.3929e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.4996e-02, -3.5577e-02,  1.4302e-02],\n",
       "                        [ 2.4874e-02,  4.3226e-02,  4.2770e-03],\n",
       "                        [-3.1416e-02,  2.6692e-02, -3.9530e-02]],\n",
       "              \n",
       "                       [[-1.9454e-02, -2.6336e-02,  1.4596e-02],\n",
       "                        [ 1.4134e-02,  1.7344e-02, -1.8363e-02],\n",
       "                        [ 2.5253e-02, -4.9183e-02,  1.2359e-01]],\n",
       "              \n",
       "                       [[ 4.3201e-02,  5.2368e-02,  3.0280e-02],\n",
       "                        [ 7.4770e-02, -1.4099e-02, -4.2542e-02],\n",
       "                        [-4.4277e-03, -2.8072e-02,  5.4179e-02]]]])),\n",
       "             ('layer4.0.bias',\n",
       "              tensor([ 0.0274, -0.0309, -0.0222, -0.0157, -0.0400, -0.0122, -0.0174,  0.0299,\n",
       "                       0.0177,  0.0112, -0.0188, -0.0382, -0.0052, -0.0101, -0.0350,  0.0398,\n",
       "                       0.0247, -0.0213, -0.0454, -0.0007, -0.0100,  0.0049,  0.0331,  0.0179,\n",
       "                      -0.0191,  0.0248, -0.0335, -0.0018, -0.0154,  0.0368, -0.0307, -0.0314,\n",
       "                       0.0375, -0.0143, -0.0501,  0.0013, -0.0012,  0.0041,  0.0024,  0.0027,\n",
       "                       0.0244,  0.0177, -0.0237, -0.0231, -0.0342,  0.0208, -0.0507,  0.0510,\n",
       "                       0.0283,  0.0317,  0.0206,  0.0069, -0.0266,  0.0112, -0.0002, -0.0147,\n",
       "                      -0.0442,  0.0165,  0.0314,  0.0228, -0.0056,  0.0050,  0.0141, -0.0032,\n",
       "                      -0.0382,  0.0303, -0.0009, -0.0236,  0.0221,  0.0229, -0.0337, -0.0045,\n",
       "                      -0.0332, -0.0233,  0.0086, -0.0233, -0.0039, -0.0113,  0.0118,  0.0238,\n",
       "                      -0.0327, -0.0447, -0.0017,  0.0059,  0.0250, -0.0438, -0.0311, -0.0413,\n",
       "                       0.0362, -0.0310,  0.0407,  0.0017, -0.0023, -0.0048,  0.0311,  0.0238,\n",
       "                      -0.0316,  0.0154,  0.0176, -0.0052, -0.0330,  0.0099, -0.0190,  0.0298,\n",
       "                      -0.0328,  0.0254, -0.0056, -0.0373,  0.0023, -0.0441,  0.0237,  0.0392,\n",
       "                      -0.0182, -0.0159, -0.0460, -0.0071, -0.0114, -0.0294, -0.0053, -0.0253,\n",
       "                       0.0365,  0.0018, -0.0221,  0.0059,  0.0349,  0.0384, -0.0045, -0.0404])),\n",
       "             ('layer4.3.weight',\n",
       "              tensor([1.0759, 1.1367, 1.0345, 1.1878, 1.1037, 1.0523, 1.1097, 1.1074, 1.0527,\n",
       "                      0.9274, 1.0797, 1.0618, 0.9897, 1.0522, 1.0594, 1.0456, 1.0752, 1.0456,\n",
       "                      1.0465, 1.0630, 1.0690, 1.0787, 0.9915, 1.0970, 1.0661, 1.0935, 1.1011,\n",
       "                      1.0924, 1.1339, 1.0639, 1.0104, 1.0214, 1.0786, 1.0715, 1.0179, 1.0742,\n",
       "                      1.0330, 1.1191, 0.9983, 1.1039, 1.1023, 1.0674, 1.0385, 1.0494, 1.0544,\n",
       "                      1.1283, 1.0972, 1.1434, 1.0564, 1.0346, 1.0651, 1.0545, 1.1005, 1.1116,\n",
       "                      1.1002, 1.1026, 1.0578, 0.9610, 1.0793, 1.1029, 1.0585, 1.0746, 1.0822,\n",
       "                      1.1118, 1.0278, 1.0063, 1.1362, 1.0218, 1.1203, 1.1281, 1.0561, 1.1492,\n",
       "                      1.0642, 1.0250, 1.1076, 1.0420, 1.0484, 1.1383, 1.0549, 1.0530, 1.0861,\n",
       "                      1.0197, 1.1143, 1.0361, 1.0600, 1.0783, 1.1063, 1.0791, 1.1224, 1.0702,\n",
       "                      1.1509, 1.0627, 1.0927, 1.0534, 1.1299, 1.0450, 1.0867, 1.0363, 1.1420,\n",
       "                      1.1815, 1.0626, 1.1081, 1.0619, 1.1591, 1.0476, 1.1353, 1.0507, 1.1378,\n",
       "                      1.0809, 1.1600, 1.0686, 1.0858, 1.0949, 1.1241, 1.1090, 0.9694, 1.0898,\n",
       "                      1.0071, 1.0887, 1.0877, 1.1729, 1.0617, 1.0127, 1.1796, 1.0162, 1.1305,\n",
       "                      1.1075, 1.0393])),\n",
       "             ('layer4.3.bias',\n",
       "              tensor([-0.0041,  0.0774, -0.0155,  0.0484,  0.1549,  0.0340,  0.0366,  0.0839,\n",
       "                       0.0692,  0.1060, -0.0052,  0.0059, -0.0010, -0.0055,  0.0878, -0.0144,\n",
       "                       0.0646,  0.1159,  0.0897,  0.0083,  0.0213, -0.0078, -0.0150,  0.0658,\n",
       "                      -0.0008,  0.0746,  0.0022,  0.0705,  0.0966,  0.0188,  0.0640,  0.0873,\n",
       "                       0.0282,  0.0718,  0.0820,  0.1198, -0.0109,  0.0036,  0.0450,  0.0918,\n",
       "                      -0.0026,  0.0585,  0.0359,  0.0395, -0.0325,  0.0125,  0.0212, -0.0376,\n",
       "                       0.0783, -0.0656, -0.0163,  0.0181, -0.0152,  0.0141, -0.0146,  0.0571,\n",
       "                       0.0460,  0.0112,  0.1891, -0.0131,  0.0574, -0.0307, -0.0806,  0.0185,\n",
       "                      -0.0197,  0.0094, -0.0109, -0.0599,  0.0077, -0.0051,  0.0234,  0.0318,\n",
       "                      -0.0104,  0.1248,  0.0543, -0.0264,  0.0150,  0.0952,  0.1563, -0.0588,\n",
       "                      -0.0486, -0.0107, -0.0127, -0.0264, -0.0334,  0.1092,  0.2096,  0.0919,\n",
       "                      -0.0052, -0.0046,  0.0516, -0.0391,  0.0017, -0.0089, -0.0189,  0.0605,\n",
       "                       0.0873,  0.0089, -0.0080,  0.0433,  0.0282,  0.1019, -0.0373,  0.0438,\n",
       "                       0.0219, -0.0263, -0.0555,  0.0651, -0.0730,  0.0888,  0.0388,  0.0837,\n",
       "                       0.0175,  0.0113, -0.0031,  0.0351,  0.0505,  0.0329, -0.0182, -0.0154,\n",
       "                      -0.0353,  0.0207,  0.0184,  0.0611,  0.0930,  0.0503,  0.0933,  0.0082])),\n",
       "             ('layer4.3.running_mean',\n",
       "              tensor([3.2511, 3.2957, 2.8012, 3.7315, 3.3863, 3.3756, 3.5222, 3.7365, 3.2812,\n",
       "                      2.1607, 3.2558, 3.4278, 2.5861, 2.6858, 3.6957, 3.6917, 3.5299, 3.4461,\n",
       "                      2.8524, 3.0777, 3.3011, 3.2510, 2.5399, 3.7074, 3.5674, 3.4445, 3.4837,\n",
       "                      3.4417, 3.9962, 3.5948, 2.2301, 3.3311, 3.5955, 2.9466, 3.2105, 3.0514,\n",
       "                      3.0607, 3.4108, 3.0248, 3.5816, 3.1855, 3.4374, 2.7219, 3.0621, 3.3917,\n",
       "                      3.3141, 3.1409, 3.9785, 3.2895, 2.8617, 3.1635, 2.8265, 3.9130, 4.1216,\n",
       "                      3.6512, 3.7155, 2.7024, 2.5912, 3.5926, 4.0103, 3.3955, 3.6217, 3.8231,\n",
       "                      4.0871, 3.0007, 3.0848, 4.2079, 2.6838, 4.1484, 3.7262, 2.4518, 3.5822,\n",
       "                      2.9819, 3.1668, 3.5799, 3.2143, 2.5193, 3.5549, 3.6318, 3.4769, 3.4128,\n",
       "                      3.4096, 3.4357, 2.1779, 2.7747, 3.7007, 3.9243, 3.4416, 3.7892, 2.9616,\n",
       "                      3.9147, 3.5042, 3.4794, 2.4764, 4.0742, 2.9214, 3.2183, 2.6820, 3.3197,\n",
       "                      4.5039, 3.7916, 3.3895, 3.4654, 3.9641, 3.1400, 3.0733, 2.8296, 4.0048,\n",
       "                      3.3619, 3.6053, 4.1932, 3.4514, 3.2149, 3.9461, 3.0852, 2.5964, 3.0044,\n",
       "                      2.6628, 3.3570, 3.7205, 4.1260, 3.1147, 2.2898, 4.1291, 3.0116, 3.5977,\n",
       "                      3.2282, 2.8107])),\n",
       "             ('layer4.3.running_var',\n",
       "              tensor([1.9554, 2.6102, 1.1810, 1.7921, 2.1358, 2.3737, 2.3915, 3.9092, 1.7684,\n",
       "                      1.9259, 1.8112, 1.9269, 1.5764, 1.3207, 1.8973, 2.3646, 1.5263, 1.9076,\n",
       "                      1.4022, 1.9018, 1.4680, 1.8178, 0.8332, 2.2415, 2.2140, 2.4870, 2.5669,\n",
       "                      2.6788, 2.4794, 1.4396, 1.8519, 1.3973, 1.4404, 1.6991, 1.6558, 1.6264,\n",
       "                      1.8664, 2.8148, 1.1577, 2.1340, 2.0627, 2.1242, 1.4372, 1.3909, 1.3283,\n",
       "                      2.2322, 1.9187, 2.1394, 1.5775, 1.1719, 2.1977, 1.8327, 2.5011, 3.0575,\n",
       "                      1.8037, 2.2192, 1.5435, 0.8786, 2.4540, 3.0685, 3.2502, 2.6830, 2.2411,\n",
       "                      1.8228, 1.2992, 2.1662, 2.1647, 1.6902, 2.3654, 2.4885, 1.4575, 2.3904,\n",
       "                      1.9902, 1.8047, 2.2346, 1.9178, 1.2114, 2.0296, 2.0903, 2.7705, 1.6319,\n",
       "                      1.4333, 2.0611, 0.8679, 1.9241, 2.1396, 3.4602, 2.3088, 2.6818, 1.3905,\n",
       "                      2.0475, 1.9056, 1.7070, 2.0544, 2.1489, 1.6073, 2.0332, 1.0811, 3.0904,\n",
       "                      3.5921, 2.0732, 1.9295, 1.9074, 3.5602, 1.7683, 1.7037, 1.4143, 2.1843,\n",
       "                      2.2669, 2.1182, 2.3160, 2.1249, 1.9087, 2.3718, 1.7303, 0.9894, 1.5470,\n",
       "                      1.5507, 2.2167, 2.0973, 2.3006, 1.9578, 2.8636, 2.9350, 1.7982, 2.7317,\n",
       "                      2.0625, 2.2550])),\n",
       "             ('layer4.3.num_batches_tracked', tensor(4502)),\n",
       "             ('fc.weight',\n",
       "              tensor([[-0.0176,  0.2824, -0.0544,  ..., -0.0709, -0.0581,  0.0761],\n",
       "                      [ 0.0780, -0.2394, -0.0676,  ..., -0.0623, -0.1078, -0.0489],\n",
       "                      [ 0.0069, -0.1380,  0.0371,  ..., -0.1275, -0.0185,  0.0424],\n",
       "                      ...,\n",
       "                      [ 0.2202, -0.0868, -0.0768,  ...,  0.1455, -0.1407,  0.0682],\n",
       "                      [-0.1935,  0.1762,  0.0552,  ...,  0.1240, -0.0462, -0.0040],\n",
       "                      [ 0.2173, -0.1439, -0.0467,  ..., -0.1601, -0.0396, -0.0627]])),\n",
       "             ('fc.bias',\n",
       "              tensor([-0.0234, -0.0206,  0.2187,  0.0635, -0.0437, -0.2749,  0.1855, -0.0570]))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ae1f198",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0317e+01,  6.6292e+00, -8.4358e+00, -1.6239e+00, -1.0330e+00,\n",
       "          1.2890e+01,  1.4720e+00,  2.6539e-01],\n",
       "        [-1.8676e-01,  1.7390e+01,  4.2369e+00, -8.2540e+00, -1.2070e+01,\n",
       "          1.7365e+00,  3.3351e+00, -9.7806e+00],\n",
       "        [-1.5576e+00, -1.7038e+00, -1.4101e+00, -3.9214e+00, -2.0914e+00,\n",
       "         -2.1380e+00,  9.1974e+00,  1.6750e+00],\n",
       "        [-4.4209e-02, -1.2661e+01, -1.1901e+01,  2.1095e+01,  5.5307e-02,\n",
       "         -3.6284e+00, -2.7841e+00,  9.9973e+00],\n",
       "        [-1.0713e+00,  1.5834e+01, -4.0176e+00, -5.4955e+00, -6.4604e+00,\n",
       "          1.4248e+00,  9.0149e-01,  1.2632e+00],\n",
       "        [ 7.0869e+00, -2.6422e+00,  1.7007e+01, -1.9197e+01, -1.5091e+00,\n",
       "         -7.3502e+00,  8.6775e-01,  2.6107e+00],\n",
       "        [-6.2766e-01, -4.2534e+00,  1.5326e+00, -3.6593e-01,  3.7531e-01,\n",
       "         -2.6595e+00, -1.1426e+01,  1.3382e+01],\n",
       "        [ 3.8789e-01, -4.6334e+00, -2.3673e+00, -3.7160e-01,  1.0157e+01,\n",
       "         -3.3115e+00, -2.4138e+00,  9.2460e-01],\n",
       "        [ 7.9312e+00, -7.8390e+00, -9.5969e+00, -3.1841e+00,  1.2406e+01,\n",
       "         -1.0145e+01,  3.4043e-01,  5.3654e+00],\n",
       "        [-9.2101e-01, -1.4945e+00, -4.7145e+00, -1.4739e+00,  5.7321e-01,\n",
       "         -5.4494e-01, -3.8830e+00,  9.4302e+00],\n",
       "        [-1.2406e+00, -6.4647e+00,  9.7399e-01,  2.2911e+00,  1.9900e+00,\n",
       "         -8.3221e+00, -4.9352e+00,  1.4288e+01],\n",
       "        [-8.5762e+00,  1.2193e+01, -4.7345e+00, -3.5526e+00, -1.0547e+01,\n",
       "          8.2210e+00,  9.7165e+00, -3.6510e+00],\n",
       "        [ 2.9593e+01, -1.6152e+01,  9.4901e+00, -3.8677e+00,  1.1053e+01,\n",
       "         -1.4973e+01, -1.0722e+01, -7.8813e+00],\n",
       "        [ 2.5965e+00, -1.1068e+01, -3.2024e+00,  1.5419e-01,  5.8626e+00,\n",
       "         -4.2353e+00,  1.7332e+01, -1.8881e+00],\n",
       "        [ 1.8467e+00,  1.9934e+00,  1.4306e+01, -3.1008e+00, -8.9611e+00,\n",
       "         -3.4960e+00, -2.0867e+00,  4.6578e+00],\n",
       "        [-2.8152e+00,  3.8246e+00, -4.0466e+00,  9.3285e+00, -2.7652e+00,\n",
       "         -6.2132e+00,  2.6145e+00,  8.6033e-01],\n",
       "        [ 1.1037e+00,  3.1338e-01,  1.0477e+01,  3.3994e+00, -6.6458e-01,\n",
       "         -1.1653e+01,  5.9761e+00, -7.6124e+00],\n",
       "        [-4.8714e+00, -5.8740e+00, -5.6068e+00, -1.2294e+00, -2.6784e+00,\n",
       "         -9.6260e-02,  4.5035e+00,  1.5062e+01],\n",
       "        [ 1.5964e+01, -4.5475e+00, -6.1565e+00,  4.9758e+00,  2.4518e+00,\n",
       "         -7.1456e+00, -6.0386e+00,  4.3130e+00],\n",
       "        [ 4.7936e+00, -7.1982e+00, -1.2076e+00,  1.4863e+00,  1.9414e+01,\n",
       "         -8.0034e+00, -1.2471e+01, -1.5357e+00],\n",
       "        [ 1.0586e+00,  1.3012e+00,  4.8914e+00, -1.6787e+00, -2.8041e+00,\n",
       "         -5.4411e-01,  8.5516e+00, -4.5139e+00],\n",
       "        [-5.9567e+00, -1.1037e+01, -2.6155e+00,  1.6329e+01,  8.5674e-02,\n",
       "         -2.7045e+00,  2.3196e+00,  5.2991e+00],\n",
       "        [ 2.4980e+00, -1.2443e+01, -1.6135e-01,  1.2727e+01,  1.5345e+00,\n",
       "         -8.4493e+00, -3.5805e+00,  4.1630e+00],\n",
       "        [ 1.1060e+00,  3.8758e+00, -3.1908e-01, -2.8387e+00, -4.4193e+00,\n",
       "         -1.2740e+00,  1.5316e+01, -4.4234e+00],\n",
       "        [-1.4754e+00, -1.0946e-01, -4.6170e+00, -5.2510e+00,  1.1085e+01,\n",
       "         -6.8867e+00, -1.0780e+00,  3.8027e+00],\n",
       "        [-1.2845e+01, -5.3026e+00, -1.2005e+00, -4.2711e-01,  1.9577e+00,\n",
       "          2.1824e+00,  1.9860e+01, -5.3288e+00],\n",
       "        [ 3.5681e+00, -5.3727e+00, -1.1391e+00,  6.7262e-01, -1.5330e-01,\n",
       "         -2.3401e-01,  4.2827e+00, -2.7301e+00],\n",
       "        [ 4.1588e+00, -1.6008e+01, -6.4460e+00,  3.1588e+00,  3.0035e+00,\n",
       "         -1.9037e+00,  1.9530e+01, -3.7134e+00],\n",
       "        [ 1.6203e+01, -6.2433e+00, -3.9938e+00, -5.8605e+00, -1.8671e+00,\n",
       "          4.3098e+00, -6.5164e+00, -1.0119e-01],\n",
       "        [ 1.4568e+00,  2.0249e+00,  6.2320e+00, -4.6406e+00, -8.3070e+00,\n",
       "          1.1747e+00,  1.3319e+01, -1.3102e+01],\n",
       "        [-3.8533e+00,  1.4490e+01, -2.2076e+00, -4.7251e+00, -4.3040e-01,\n",
       "          1.7323e+00, -1.5830e+00, -1.0251e+00],\n",
       "        [-1.4345e+01,  1.5391e+01, -3.0047e+00, -7.9322e+00, -3.2277e-01,\n",
       "          1.0760e+00,  3.8098e+00, -2.4661e+00],\n",
       "        [ 5.6540e+00, -7.6239e+00,  2.6166e-01, -3.1635e+00, -1.6156e+00,\n",
       "         -4.9806e+00, -2.4574e+00,  1.2427e+01],\n",
       "        [-8.3545e+00,  1.3980e+01,  1.9342e+00, -8.0128e+00, -6.5151e-01,\n",
       "         -3.0261e+00,  4.8557e+00, -1.4511e+00],\n",
       "        [-6.2077e+00,  2.3123e+00, -1.2217e+00,  1.2744e+01, -5.5910e-01,\n",
       "         -2.8984e+00, -3.3104e+00,  2.7359e+00],\n",
       "        [-5.6767e+00, -4.3705e+00, -9.6511e+00,  1.7686e+01,  3.9880e+00,\n",
       "         -3.5699e+00, -4.7358e+00,  4.8586e+00],\n",
       "        [ 1.1628e+00, -2.9303e+00,  1.2514e+01, -3.9996e+00, -2.1274e+00,\n",
       "         -6.2494e+00, -3.7219e+00,  3.3248e+00],\n",
       "        [ 5.0723e-01, -7.5121e+00,  1.4600e+01,  2.7043e+00,  1.3347e+00,\n",
       "         -5.1040e+00, -3.7503e+00, -3.9823e+00],\n",
       "        [-4.3969e+00, -1.8298e+00, -1.2479e+00, -8.1544e-01,  9.5394e+00,\n",
       "          1.4442e+00, -2.4673e+00, -2.8623e+00],\n",
       "        [ 3.4681e+00,  2.9192e+00,  1.5431e+01, -1.5581e+00, -4.1694e-01,\n",
       "         -6.6326e+00, -4.7616e+00, -6.4616e+00],\n",
       "        [-1.3920e+00, -4.5413e+00,  4.8523e+00, -6.0127e-01, -6.7728e+00,\n",
       "         -5.2115e+00,  1.1275e+01,  3.4796e+00],\n",
       "        [ 1.8171e+00,  1.5078e+01, -9.7935e-01, -7.8553e+00,  7.6179e-01,\n",
       "         -2.2698e+00, -7.3511e-01, -4.8573e+00],\n",
       "        [ 1.9462e+00, -6.3839e-01, -2.2639e-01, -5.5759e+00,  2.5666e+00,\n",
       "          1.7903e+00,  5.3788e+00, -5.5823e+00],\n",
       "        [ 2.2296e+01, -2.2556e+00, -4.6250e+00,  2.6935e+00, -2.4915e+00,\n",
       "         -6.0719e+00, -5.1504e-01, -1.1517e+01],\n",
       "        [-1.7609e+01,  1.1296e+01,  4.6684e+00, -6.0477e-01, -3.1606e+00,\n",
       "          2.3786e+00,  6.5736e+00, -5.6703e+00],\n",
       "        [-2.2311e+00, -1.7575e+00, -1.5032e+00, -4.1891e+00, -6.1376e+00,\n",
       "          9.8068e-03,  1.4435e+01,  2.5346e+00],\n",
       "        [-1.8296e+00, -1.8299e+00,  1.5636e+01,  2.7864e+00,  4.3563e+00,\n",
       "         -1.0389e+01, -1.3295e+01,  2.2078e+00],\n",
       "        [ 1.3156e+01, -7.3042e+00, -1.3577e+00,  3.1636e-01, -1.4971e+00,\n",
       "         -4.1945e+00, -2.9724e+00,  3.8547e+00],\n",
       "        [ 9.0049e+00, -7.4293e+00, -8.7239e+00,  1.2260e+01,  3.2458e+00,\n",
       "         -3.3194e+00, -5.0935e+00,  2.5267e+00],\n",
       "        [-1.4995e+00, -4.7762e+00,  1.1835e+01, -5.1997e+00,  6.6147e+00,\n",
       "         -1.2445e+01, -5.6956e+00,  5.4423e+00],\n",
       "        [ 5.2990e+00, -4.8267e+00,  2.0212e+01, -5.4796e+00, -3.8692e-01,\n",
       "         -9.3558e+00, -1.2053e+01,  5.9399e+00],\n",
       "        [-4.3437e+00, -7.1073e+00, -5.9578e+00,  1.9408e+01, -1.4800e+00,\n",
       "         -3.2839e+00,  5.0265e+00,  2.1442e+00],\n",
       "        [ 1.0525e+00, -6.4375e+00, -6.0618e+00,  1.5709e+01,  1.7020e-01,\n",
       "         -3.8236e-01, -1.0096e+01,  2.3067e+00],\n",
       "        [ 1.0015e+00, -1.1127e+01, -4.9276e+00,  1.2364e+00,  2.1559e+00,\n",
       "         -1.2547e+00, -2.1549e+00,  1.4252e+01],\n",
       "        [-5.5869e+00,  7.0317e-01,  3.2800e+00, -1.2312e+00,  2.0178e+00,\n",
       "         -1.0811e+01, -1.8715e+00,  1.7287e+01],\n",
       "        [-3.2399e+00, -2.9367e+00, -7.1576e+00,  8.2115e+00, -2.5899e-01,\n",
       "          1.1574e+00, -1.3101e+00,  2.7913e+00],\n",
       "        [-3.8652e+00, -2.3294e+00, -7.4675e+00,  4.7525e-01, -2.9848e+00,\n",
       "          4.1239e+00,  2.5103e+01, -5.6536e+00],\n",
       "        [-3.9500e+00, -6.3346e+00, -3.0940e+00,  1.3968e+01, -5.3301e+00,\n",
       "          1.8518e+00,  7.4159e-01,  1.2401e+00],\n",
       "        [ 5.4927e+00, -1.2922e+01, -3.9509e+00, -3.5906e+00,  1.7761e+01,\n",
       "         -3.0964e+00, -5.0965e-01, -2.7126e+00],\n",
       "        [ 4.4169e+00, -1.2157e+01, -4.0314e+00,  3.7765e+00,  5.4642e+00,\n",
       "          3.7329e-01, -1.1960e+01,  1.9566e+01],\n",
       "        [-3.0219e+00, -1.1180e+01, -5.9953e+00,  2.2110e+01, -1.5380e+00,\n",
       "         -4.0039e+00,  3.2589e-01,  4.8667e+00],\n",
       "        [ 6.5779e+00, -1.1999e+01,  1.2785e+01,  3.3560e+00,  2.8372e-01,\n",
       "         -1.0344e+01, -4.0433e+00,  1.9030e+00],\n",
       "        [ 2.8682e+00, -6.6724e+00, -4.1750e+00, -3.2390e+00,  2.1352e+00,\n",
       "         -1.3764e+00, -3.3313e+00,  1.4659e+01],\n",
       "        [ 5.5563e+00, -5.3792e+00,  1.9053e-01,  4.0460e+00, -1.0848e+01,\n",
       "         -1.1434e+01, -4.6896e-01,  2.1334e+01]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17152393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 563)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77bdd78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor(np.expand_dims(x_test[1], 0)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42129e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.7910,  0.3488, -6.5197,  8.5065, -5.1568, -8.0247, 14.6517,  2.8421]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02f3a709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model(t),1).cpu().detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e74b81eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 432/432 [00:12<00:00, 34.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_len:432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "predicts = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(x_test):\n",
    "        ###test data를 하나씩 불러와서 학습된 모델로 추론 후 predicts array에 저장합니다.\n",
    "        t = torch.Tensor(np.expand_dims(data, 0)).to(device)\n",
    "        H = model(t)\n",
    "        predict = torch.argmax(H, 1).cpu().detach().numpy()[0]\n",
    "        predicts.append(predict)\n",
    "        \n",
    "print(f'predict_len:{len(predicts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbc5623d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts[53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "846fe720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sad', 'sad', 'calm', 'calm', 'disgust', 'sad', 'disgust', 'angry',\n",
       "       'happy', 'sad', 'fearful', 'angry', 'surprised', 'surprised',\n",
       "       'surprised', 'sad', 'disgust', 'calm', 'happy', 'sad', 'angry',\n",
       "       'sad', 'fearful', 'neutral', 'surprised', 'sad', 'happy', 'happy',\n",
       "       'happy', 'neutral', 'disgust', 'surprised', 'calm', 'sad',\n",
       "       'disgust', 'happy', 'calm', 'happy', 'disgust', 'sad', 'happy',\n",
       "       'disgust', 'fearful', 'angry', 'disgust', 'angry', 'neutral',\n",
       "       'surprised', 'surprised', 'happy', 'happy', 'happy', 'disgust',\n",
       "       'happy', 'angry', 'calm', 'angry', 'angry', 'surprised', 'calm',\n",
       "       'sad', 'angry', 'surprised', 'fearful', 'sad', 'angry',\n",
       "       'surprised', 'disgust', 'fearful', 'happy', 'angry', 'surprised',\n",
       "       'angry', 'surprised', 'sad', 'happy', 'calm', 'happy', 'surprised',\n",
       "       'happy', 'sad', 'fearful', 'disgust', 'calm', 'calm', 'angry',\n",
       "       'angry', 'disgust', 'disgust', 'disgust', 'happy', 'sad', 'angry',\n",
       "       'neutral', 'fearful', 'calm', 'fearful', 'happy', 'sad', 'fearful',\n",
       "       'happy', 'calm', 'disgust', 'calm', 'neutral', 'angry', 'calm',\n",
       "       'fearful', 'angry', 'happy', 'neutral', 'calm', 'neutral',\n",
       "       'surprised', 'fearful', 'disgust', 'surprised', 'happy', 'fearful',\n",
       "       'fearful', 'angry', 'calm', 'calm', 'happy', 'surprised', 'calm',\n",
       "       'fearful', 'calm', 'disgust', 'sad', 'calm', 'angry', 'sad',\n",
       "       'disgust', 'happy', 'surprised', 'happy', 'happy', 'calm', 'happy',\n",
       "       'disgust', 'happy', 'calm', 'neutral', 'sad', 'disgust',\n",
       "       'surprised', 'happy', 'fearful', 'surprised', 'fearful', 'sad',\n",
       "       'disgust', 'sad', 'sad', 'calm', 'neutral', 'happy', 'surprised',\n",
       "       'angry', 'sad', 'fearful', 'fearful', 'happy', 'angry', 'calm',\n",
       "       'neutral', 'angry', 'surprised', 'angry', 'angry', 'angry',\n",
       "       'disgust', 'angry', 'happy', 'angry', 'happy', 'surprised',\n",
       "       'disgust', 'angry', 'calm', 'happy', 'calm', 'disgust', 'happy',\n",
       "       'disgust', 'fearful', 'calm', 'calm', 'disgust', 'disgust', 'calm',\n",
       "       'calm', 'surprised', 'angry', 'happy', 'angry', 'neutral', 'angry',\n",
       "       'disgust', 'angry', 'calm', 'neutral', 'disgust', 'disgust',\n",
       "       'fearful', 'disgust', 'fearful', 'angry', 'calm', 'calm', 'angry',\n",
       "       'angry', 'angry', 'surprised', 'calm', 'disgust', 'angry', 'sad',\n",
       "       'angry', 'surprised', 'disgust', 'disgust', 'disgust', 'fearful',\n",
       "       'fearful', 'fearful', 'calm', 'angry', 'fearful', 'fearful', 'sad',\n",
       "       'calm', 'surprised', 'calm', 'angry', 'happy', 'fearful',\n",
       "       'surprised', 'surprised', 'calm', 'disgust', 'fearful', 'disgust',\n",
       "       'sad', 'angry', 'surprised', 'disgust', 'surprised', 'happy',\n",
       "       'calm', 'neutral', 'angry', 'surprised', 'surprised', 'fearful',\n",
       "       'sad', 'disgust', 'calm', 'surprised', 'angry', 'calm', 'sad',\n",
       "       'angry', 'fearful', 'sad', 'sad', 'happy', 'disgust', 'neutral',\n",
       "       'fearful', 'sad', 'happy', 'calm', 'happy', 'angry', 'surprised',\n",
       "       'disgust', 'fearful', 'fearful', 'angry', 'surprised', 'surprised',\n",
       "       'surprised', 'surprised', 'surprised', 'sad', 'calm', 'neutral',\n",
       "       'happy', 'sad', 'neutral', 'disgust', 'fearful', 'surprised',\n",
       "       'fearful', 'sad', 'surprised', 'fearful', 'happy', 'sad', 'sad',\n",
       "       'happy', 'angry', 'fearful', 'fearful', 'sad', 'fearful', 'calm',\n",
       "       'surprised', 'fearful', 'fearful', 'neutral', 'fearful', 'angry',\n",
       "       'fearful', 'happy', 'neutral', 'disgust', 'happy', 'sad',\n",
       "       'surprised', 'calm', 'surprised', 'calm', 'angry', 'happy',\n",
       "       'neutral', 'surprised', 'disgust', 'happy', 'surprised', 'calm',\n",
       "       'surprised', 'disgust', 'happy', 'angry', 'happy', 'angry',\n",
       "       'disgust', 'disgust', 'surprised', 'neutral', 'surprised', 'angry',\n",
       "       'surprised', 'neutral', 'neutral', 'happy', 'fearful', 'calm',\n",
       "       'happy', 'disgust', 'angry', 'happy', 'neutral', 'surprised',\n",
       "       'happy', 'fearful', 'sad', 'fearful', 'neutral', 'angry', 'angry',\n",
       "       'neutral', 'neutral', 'happy', 'disgust', 'angry', 'disgust',\n",
       "       'disgust', 'disgust', 'calm', 'calm', 'sad', 'angry', 'angry',\n",
       "       'fearful', 'sad', 'sad', 'happy', 'calm', 'happy', 'happy',\n",
       "       'happy', 'fearful', 'neutral', 'calm', 'disgust', 'angry',\n",
       "       'fearful', 'neutral', 'calm', 'angry', 'fearful', 'calm', 'happy',\n",
       "       'surprised', 'angry', 'calm', 'happy', 'disgust', 'happy', 'calm',\n",
       "       'angry', 'surprised', 'neutral', 'happy', 'calm', 'sad', 'disgust',\n",
       "       'angry', 'happy', 'happy', 'neutral', 'disgust', 'surprised',\n",
       "       'fearful', 'angry', 'calm', 'calm', 'disgust', 'neutral',\n",
       "       'disgust', 'disgust', 'calm', 'surprised', 'neutral', 'fearful',\n",
       "       'surprised', 'calm', 'angry'], dtype='<U9')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###저장된 예측값을 위에서 사용한 label encoder를 이용해 다시 문자열로 역변환합니다.\n",
    "predicts1 = le.inverse_transform(predicts)\n",
    "predicts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "699b78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts1 = []\n",
    "\n",
    "t = torch.Tensor(np.expand_dims(x_test[0], 0)).to(device)\n",
    "H = model(t)\n",
    "predict1 = torch.argmax(H, 1).cpu().detach().numpy()[0]\n",
    "predicts1.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1a7e4b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "049ade63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sad'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = le.inverse_transform(predicts)\n",
    "answer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f890a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
